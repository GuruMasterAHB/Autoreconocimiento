{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7028419,"sourceType":"datasetVersion","datasetId":4042417}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Para llevar el registro\n!pip install -q comet_ml\nimport comet_ml\ncomet_ml.init(project_name = 'Regularizer')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:53:11.948053Z","iopub.execute_input":"2023-11-25T05:53:11.948844Z","iopub.status.idle":"2023-11-25T05:53:53.025702Z","shell.execute_reply.started":"2023-11-25T05:53:11.948812Z","shell.execute_reply":"2023-11-25T05:53:53.024766Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mPlease paste your Comet API key from https://www.comet.com/api/my/settings/\n(api key may not show as you type)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Comet API key:  ·························\n"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Conv2D, MaxPooling2D, Concatenate, PReLU\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adadelta\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.regularizers import l2","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:53:53.027332Z","iopub.execute_input":"2023-11-25T05:53:53.027617Z","iopub.status.idle":"2023-11-25T05:54:04.870493Z","shell.execute_reply.started":"2023-11-25T05:53:53.027591Z","shell.execute_reply":"2023-11-25T05:54:04.869679Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Se crea el experimento en Comet\nexperiment = comet_ml.Experiment(\n    auto_histogram_weight_logging = True,\n    auto_histogram_gradient_logging = True,\n    auto_histogram_activation_logging = True,\n    log_code = True\n)\nexperiment.set_name('Try_6 [from: FunctionalAPI]')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:54:04.871702Z","iopub.execute_input":"2023-11-25T05:54:04.872435Z","iopub.status.idle":"2023-11-25T05:54:09.104779Z","shell.execute_reply.started":"2023-11-25T05:54:04.872398Z","shell.execute_reply":"2023-11-25T05:54:09.103747Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/gurumasterahb/regularizer/43be4131cd8641718803b2160871e5cb\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cargar los datos de los txt\nfile_attr = os.path.join('/kaggle/input/img-align-celeba-partition/attr.csv')\nattr = pd.read_csv(file_attr)\n\n# Imágenes\ni_test = '/kaggle/input/img-align-celeba-partition/align_partition/align_test'\ni_train = '/kaggle/input/img-align-celeba-partition/align_partition/align_train'\ni_val = '/kaggle/input/img-align-celeba-partition/align_partition/align_val'","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:54:09.107335Z","iopub.execute_input":"2023-11-25T05:54:09.107714Z","iopub.status.idle":"2023-11-25T05:54:10.009724Z","shell.execute_reply.started":"2023-11-25T05:54:09.107676Z","shell.execute_reply":"2023-11-25T05:54:10.008788Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Parámetros\ni_width = int(178 * 1.2)\ni_height = int(218 * 1.2)\ninput_shape = (i_width, i_height, 3)\n\nparameters = {\n    'num_class' : 38,\n    'epochs' : 60,\n    'batch_size' : 64,\n    'loss' : 'binary_crossentropy',\n    'optimizer' : 'RMSprop',\n    'num_train' : 162770,\n    'num_val' : 19867,\n    'num_test' : 19962,\n}\nexperiment.log_parameters(parameters)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:54:10.011286Z","iopub.execute_input":"2023-11-25T05:54:10.011658Z","iopub.status.idle":"2023-11-25T05:54:10.112145Z","shell.execute_reply.started":"2023-11-25T05:54:10.011622Z","shell.execute_reply":"2023-11-25T05:54:10.111157Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Solo toma el entero\nepoch_steps = parameters['num_train'] // (parameters['batch_size'] * 6) # Training\nval_steps = parameters['num_val'] // (parameters['batch_size'] * 6) # Validation\ntest_steps = parameters['num_test'] // (parameters['batch_size'] * 6) # Testing","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:54:10.114028Z","iopub.execute_input":"2023-11-25T05:54:10.114500Z","iopub.status.idle":"2023-11-25T05:54:10.119887Z","shell.execute_reply.started":"2023-11-25T05:54:10.114465Z","shell.execute_reply":"2023-11-25T05:54:10.118795Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"gen_train = ImageDataGenerator(rescale = 1./255.)\ntrain = gen_train.flow_from_dataframe(\n    attr,\n    directory = i_train,\n    x_col = attr.columns[0],  # Nombre de la columna que contiene los nombres de las imágenes\n    y_col = attr.columns[1:],  # Lista de nombres de las columnas de atributos\n    target_size = (i_width, i_height),\n    batch_size = parameters['batch_size'],\n    class_mode = 'raw',\n    shuffle = True\n)\n\ngen_val = ImageDataGenerator(rescale = 1./255.)\nval = gen_val.flow_from_dataframe(\n    attr,\n    directory = i_val,\n    x_col = attr.columns[0],  # Nombre de la columna que contiene los nombres de las imágenes\n    y_col = attr.columns[1:],  # Lista de nombres de las columnas de atributos\n    target_size = (i_width, i_height),\n    batch_size = parameters['batch_size'],\n    class_mode = 'raw',\n    shuffle = True\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:54:10.121277Z","iopub.execute_input":"2023-11-25T05:54:10.121614Z","iopub.status.idle":"2023-11-25T06:06:21.983005Z","shell.execute_reply.started":"2023-11-25T05:54:10.121581Z","shell.execute_reply":"2023-11-25T06:06:21.982023Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 162770 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 39829 invalid image filename(s) in x_col=\"202599\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 19867 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 182732 invalid image filename(s) in x_col=\"202599\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Arquitectura\n# # Functional API\n# inputs = Input(shape = input_shape)\n\n# conv1 = Conv2D(32, (3,3), activation = 'relu')(inputs)\n# mpool1 = MaxPooling2D(pool_size = (2,2))(conv1)\n\n# conv2 = Conv2D(64, (3,3), activation = 'relu', kernel_regularizer = l2(0.0001))(mpool1)\n# mpool2 = MaxPooling2D(pool_size = (2,2))(conv2)\n\n# conv3 = Conv2D(128, (3,3), activation = 'relu')(mpool2)\n# mpool3 = MaxPooling2D(pool_size = (2,2))(conv3)\n\n# conv4 = Conv2D(256, (3,3), activation = 'relu')(mpool3)\n# mpool4 = MaxPooling2D(pool_size = (2,2))(conv4)\n\n# conv5 = Conv2D(512, (3,3), activation = 'relu', kernel_regularizer = l2(0.0001))(mpool4)\n# mpool5 = MaxPooling2D(pool_size = (2,2))(conv5)\n\n# conv6 = Conv2D(256, (3,3), activation = 'relu')(mpool5)\n# mpool6 = MaxPooling2D(pool_size = (2,2))(conv6)\n\n# x_1 = Flatten()(mpool6)\n\n# x_2 = Dense(1024, activation = 'relu')(x_1)\n\n# x_3 = Dense(1024, activation = 'relu')(x_2)\n# x_4 = Dropout(0.15)(x_3)\n\n# x_5 = Dense(512, activation = 'PReLU', kernel_regularizer = l2(0.0001))(x_4)\n\n# x_6 = Dense(256, activation = 'PReLU')(x_5)\n\n# x_7 = Dense(128, activation = 'relu')(x_6)\n\n# x_out = Dense(parameters['num_class'], activation = 'sigmoid')(x_7)\n\n# model = tf.keras.Model(inputs = inputs, outputs = x_out)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:06:21.984438Z","iopub.execute_input":"2023-11-25T06:06:21.985152Z","iopub.status.idle":"2023-11-25T06:06:21.990446Z","shell.execute_reply.started":"2023-11-25T06:06:21.985115Z","shell.execute_reply":"2023-11-25T06:06:21.989438Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3,3), activation = 'relu', input_shape = input_shape))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(64, (3,3), activation = 'relu', kernel_regularizer = l2(0.0001)))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(128, (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(256, (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(512, (3,3), activation = 'relu', kernel_regularizer = l2(0.0001)))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(256, (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1024, activation = 'relu'))\n\nmodel.add(Dense(1024, activation = 'relu'))\nmodel.add(Dropout(0.15))\n          \nmodel.add(Dense(512, activation = 'PReLU', kernel_regularizer = l2(0.0001)))\n\nmodel.add(Dense(256, activation = 'PReLU'))\n\nmodel.add(Dense(128, activation = 'relu'))\n\nmodel.add(Dense(parameters['num_class'], activation = 'sigmoid'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:11:33.123584Z","iopub.execute_input":"2023-11-25T06:11:33.124473Z","iopub.status.idle":"2023-11-25T06:11:33.394727Z","shell.execute_reply.started":"2023-11-25T06:11:33.124440Z","shell.execute_reply":"2023-11-25T06:11:33.393815Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_1 (Conv2D)           (None, 211, 259, 32)      896       \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 105, 129, 32)      0         \n g2D)                                                            \n                                                                 \n conv2d_2 (Conv2D)           (None, 103, 127, 64)      18496     \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 51, 63, 64)        0         \n g2D)                                                            \n                                                                 \n conv2d_3 (Conv2D)           (None, 49, 61, 128)       73856     \n                                                                 \n max_pooling2d_3 (MaxPoolin  (None, 24, 30, 128)       0         \n g2D)                                                            \n                                                                 \n conv2d_4 (Conv2D)           (None, 22, 28, 256)       295168    \n                                                                 \n max_pooling2d_4 (MaxPoolin  (None, 11, 14, 256)       0         \n g2D)                                                            \n                                                                 \n conv2d_5 (Conv2D)           (None, 9, 12, 512)        1180160   \n                                                                 \n max_pooling2d_5 (MaxPoolin  (None, 4, 6, 512)         0         \n g2D)                                                            \n                                                                 \n conv2d_6 (Conv2D)           (None, 2, 4, 256)         1179904   \n                                                                 \n max_pooling2d_6 (MaxPoolin  (None, 1, 2, 256)         0         \n g2D)                                                            \n                                                                 \n flatten (Flatten)           (None, 512)               0         \n                                                                 \n dense (Dense)               (None, 1024)              525312    \n                                                                 \n dense_1 (Dense)             (None, 1024)              1049600   \n                                                                 \n dropout (Dropout)           (None, 1024)              0         \n                                                                 \n dense_2 (Dense)             (None, 512)               525312    \n                                                                 \n dense_3 (Dense)             (None, 256)               131584    \n                                                                 \n dense_4 (Dense)             (None, 128)               32896     \n                                                                 \n dense_5 (Dense)             (None, 38)                4902      \n                                                                 \n=================================================================\nTotal params: 5018086 (19.14 MB)\nTrainable params: 5018086 (19.14 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Checkpoint para el mejor modelo (val_accuracy)\nfilepath = 'best_val_loss.h5'\ncheckpoint = ModelCheckpoint(\n    filepath,\n    monitor = 'val_loss',\n    verbose = 1,\n    save_best_only = True,\n    mode = 'min'\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:11:36.519825Z","iopub.execute_input":"2023-11-25T06:11:36.520230Z","iopub.status.idle":"2023-11-25T06:11:36.525590Z","shell.execute_reply.started":"2023-11-25T06:11:36.520196Z","shell.execute_reply":"2023-11-25T06:11:36.524576Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Compilación y entrenamiento\nmodel.compile(\n    loss = parameters['loss'],\n    optimizer = RMSprop(learning_rate = 0.001),\n    metrics = ['binary_accuracy']\n)\n\nmodel.fit(\n    train,\n    batch_size = parameters['batch_size'],\n    epochs = parameters['epochs'],\n    verbose = 1,\n    validation_data = val,\n    steps_per_epoch = epoch_steps,\n    validation_steps = val_steps,\n    callbacks = [checkpoint]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:11:38.389898Z","iopub.execute_input":"2023-11-25T06:11:38.390661Z","iopub.status.idle":"2023-11-25T08:08:55.324400Z","shell.execute_reply.started":"2023-11-25T06:11:38.390623Z","shell.execute_reply":"2023-11-25T08:08:55.323372Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m auto_histogram_gradient_logging is True, but inputs and targets are not available; unable to log gradients\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m auto_histogram_activation_logging is True, but inputs are not available; unable to log activations\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/60\n423/423 [==============================] - ETA: 0s - loss: 0.5220 - binary_accuracy: 0.8090\nEpoch 1: val_loss improved from inf to 0.45545, saving model to best_val_loss.h5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"423/423 [==============================] - 281s 634ms/step - loss: 0.5220 - binary_accuracy: 0.8090 - val_loss: 0.4555 - val_binary_accuracy: 0.8274\nEpoch 2/60\n423/423 [==============================] - ETA: 0s - loss: 0.4099 - binary_accuracy: 0.8428\nEpoch 2: val_loss improved from 0.45545 to 0.36468, saving model to best_val_loss.h5\n423/423 [==============================] - 261s 618ms/step - loss: 0.4099 - binary_accuracy: 0.8428 - val_loss: 0.3647 - val_binary_accuracy: 0.8609\nEpoch 3/60\n423/423 [==============================] - ETA: 0s - loss: 0.3461 - binary_accuracy: 0.8646\nEpoch 3: val_loss improved from 0.36468 to 0.32714, saving model to best_val_loss.h5\n423/423 [==============================] - 221s 522ms/step - loss: 0.3461 - binary_accuracy: 0.8646 - val_loss: 0.3271 - val_binary_accuracy: 0.8714\nEpoch 4/60\n423/423 [==============================] - ETA: 0s - loss: 0.3159 - binary_accuracy: 0.8723\nEpoch 4: val_loss improved from 0.32714 to 0.29872, saving model to best_val_loss.h5\n423/423 [==============================] - 198s 469ms/step - loss: 0.3159 - binary_accuracy: 0.8723 - val_loss: 0.2987 - val_binary_accuracy: 0.8775\nEpoch 5/60\n423/423 [==============================] - ETA: 0s - loss: 0.2976 - binary_accuracy: 0.8772\nEpoch 5: val_loss did not improve from 0.29872\n423/423 [==============================] - 184s 435ms/step - loss: 0.2976 - binary_accuracy: 0.8772 - val_loss: 0.3117 - val_binary_accuracy: 0.8715\nEpoch 6/60\n423/423 [==============================] - ETA: 0s - loss: 0.2832 - binary_accuracy: 0.8823\nEpoch 6: val_loss improved from 0.29872 to 0.27675, saving model to best_val_loss.h5\n423/423 [==============================] - 164s 388ms/step - loss: 0.2832 - binary_accuracy: 0.8823 - val_loss: 0.2767 - val_binary_accuracy: 0.8860\nEpoch 7/60\n423/423 [==============================] - ETA: 0s - loss: 0.2748 - binary_accuracy: 0.8848\nEpoch 7: val_loss did not improve from 0.27675\n423/423 [==============================] - 152s 359ms/step - loss: 0.2748 - binary_accuracy: 0.8848 - val_loss: 0.2792 - val_binary_accuracy: 0.8840\nEpoch 8/60\n423/423 [==============================] - ETA: 0s - loss: 0.2670 - binary_accuracy: 0.8873\nEpoch 8: val_loss improved from 0.27675 to 0.25738, saving model to best_val_loss.h5\n423/423 [==============================] - 144s 341ms/step - loss: 0.2670 - binary_accuracy: 0.8873 - val_loss: 0.2574 - val_binary_accuracy: 0.8935\nEpoch 9/60\n423/423 [==============================] - ETA: 0s - loss: 0.2593 - binary_accuracy: 0.8910\nEpoch 9: val_loss improved from 0.25738 to 0.25646, saving model to best_val_loss.h5\n423/423 [==============================] - 135s 319ms/step - loss: 0.2593 - binary_accuracy: 0.8910 - val_loss: 0.2565 - val_binary_accuracy: 0.8936\nEpoch 10/60\n423/423 [==============================] - ETA: 0s - loss: 0.2573 - binary_accuracy: 0.8922\nEpoch 10: val_loss improved from 0.25646 to 0.24520, saving model to best_val_loss.h5\n423/423 [==============================] - 125s 296ms/step - loss: 0.2573 - binary_accuracy: 0.8922 - val_loss: 0.2452 - val_binary_accuracy: 0.8979\nEpoch 11/60\n423/423 [==============================] - ETA: 0s - loss: 0.2515 - binary_accuracy: 0.8945\nEpoch 11: val_loss did not improve from 0.24520\n423/423 [==============================] - 121s 285ms/step - loss: 0.2515 - binary_accuracy: 0.8945 - val_loss: 0.2530 - val_binary_accuracy: 0.8952\nEpoch 12/60\n423/423 [==============================] - ETA: 0s - loss: 0.2481 - binary_accuracy: 0.8958\nEpoch 12: val_loss improved from 0.24520 to 0.24446, saving model to best_val_loss.h5\n423/423 [==============================] - 115s 272ms/step - loss: 0.2481 - binary_accuracy: 0.8958 - val_loss: 0.2445 - val_binary_accuracy: 0.8983\nEpoch 13/60\n423/423 [==============================] - ETA: 0s - loss: 0.2463 - binary_accuracy: 0.8967\nEpoch 13: val_loss improved from 0.24446 to 0.24398, saving model to best_val_loss.h5\n423/423 [==============================] - 111s 261ms/step - loss: 0.2463 - binary_accuracy: 0.8967 - val_loss: 0.2440 - val_binary_accuracy: 0.8995\nEpoch 14/60\n423/423 [==============================] - ETA: 0s - loss: 0.2433 - binary_accuracy: 0.8982\nEpoch 14: val_loss improved from 0.24398 to 0.24046, saving model to best_val_loss.h5\n423/423 [==============================] - 105s 248ms/step - loss: 0.2433 - binary_accuracy: 0.8982 - val_loss: 0.2405 - val_binary_accuracy: 0.9013\nEpoch 15/60\n423/423 [==============================] - ETA: 0s - loss: 0.2420 - binary_accuracy: 0.8988\nEpoch 15: val_loss improved from 0.24046 to 0.24021, saving model to best_val_loss.h5\n423/423 [==============================] - 102s 241ms/step - loss: 0.2420 - binary_accuracy: 0.8988 - val_loss: 0.2402 - val_binary_accuracy: 0.9004\nEpoch 16/60\n423/423 [==============================] - ETA: 0s - loss: 0.2407 - binary_accuracy: 0.8993\nEpoch 16: val_loss did not improve from 0.24021\n423/423 [==============================] - 99s 234ms/step - loss: 0.2407 - binary_accuracy: 0.8993 - val_loss: 0.2444 - val_binary_accuracy: 0.8993\nEpoch 17/60\n423/423 [==============================] - ETA: 0s - loss: 0.2374 - binary_accuracy: 0.9010\nEpoch 17: val_loss improved from 0.24021 to 0.23759, saving model to best_val_loss.h5\n423/423 [==============================] - 99s 233ms/step - loss: 0.2374 - binary_accuracy: 0.9010 - val_loss: 0.2376 - val_binary_accuracy: 0.9025\nEpoch 18/60\n373/423 [=========================>....] - ETA: 10s - loss: 0.2355 - binary_accuracy: 0.9018\nEpoch 19: val_loss improved from 0.23759 to 0.23338, saving model to best_val_loss.h5\n423/423 [==============================] - 100s 235ms/step - loss: 0.2345 - binary_accuracy: 0.9024 - val_loss: 0.2334 - val_binary_accuracy: 0.9035\nEpoch 20/60\n423/423 [==============================] - ETA: 0s - loss: 0.2339 - binary_accuracy: 0.9030\nEpoch 20: val_loss improved from 0.23338 to 0.23134, saving model to best_val_loss.h5\n423/423 [==============================] - 96s 227ms/step - loss: 0.2339 - binary_accuracy: 0.9030 - val_loss: 0.2313 - val_binary_accuracy: 0.9056\nEpoch 21/60\n423/423 [==============================] - ETA: 0s - loss: 0.2327 - binary_accuracy: 0.9033\nEpoch 21: val_loss did not improve from 0.23134\n423/423 [==============================] - 96s 226ms/step - loss: 0.2327 - binary_accuracy: 0.9033 - val_loss: 0.2320 - val_binary_accuracy: 0.9046\nEpoch 22/60\n423/423 [==============================] - ETA: 0s - loss: 0.2312 - binary_accuracy: 0.9044\nEpoch 22: val_loss improved from 0.23134 to 0.22721, saving model to best_val_loss.h5\n423/423 [==============================] - 95s 225ms/step - loss: 0.2312 - binary_accuracy: 0.9044 - val_loss: 0.2272 - val_binary_accuracy: 0.9072\nEpoch 23/60\n423/423 [==============================] - ETA: 0s - loss: 0.2299 - binary_accuracy: 0.9049\nEpoch 24: val_loss did not improve from 0.22721\n423/423 [==============================] - 95s 224ms/step - loss: 0.2299 - binary_accuracy: 0.9049 - val_loss: 0.2288 - val_binary_accuracy: 0.9069\nEpoch 25/60\n423/423 [==============================] - ETA: 0s - loss: 0.2277 - binary_accuracy: 0.9061\nEpoch 25: val_loss improved from 0.22721 to 0.22598, saving model to best_val_loss.h5\n423/423 [==============================] - 95s 224ms/step - loss: 0.2277 - binary_accuracy: 0.9061 - val_loss: 0.2260 - val_binary_accuracy: 0.9091\nEpoch 26/60\n423/423 [==============================] - ETA: 0s - loss: 0.2275 - binary_accuracy: 0.9060\nEpoch 26: val_loss did not improve from 0.22598\n423/423 [==============================] - 95s 223ms/step - loss: 0.2275 - binary_accuracy: 0.9060 - val_loss: 0.2287 - val_binary_accuracy: 0.9069\nEpoch 27/60\n423/423 [==============================] - ETA: 0s - loss: 0.2278 - binary_accuracy: 0.9061\nEpoch 27: val_loss did not improve from 0.22598\n423/423 [==============================] - 94s 222ms/step - loss: 0.2278 - binary_accuracy: 0.9061 - val_loss: 0.2264 - val_binary_accuracy: 0.9080\nEpoch 28/60\n423/423 [==============================] - ETA: 0s - loss: 0.2261 - binary_accuracy: 0.9071\nEpoch 28: val_loss did not improve from 0.22598\n423/423 [==============================] - 96s 226ms/step - loss: 0.2261 - binary_accuracy: 0.9071 - val_loss: 0.2282 - val_binary_accuracy: 0.9065\nEpoch 29/60\n423/423 [==============================] - ETA: 0s - loss: 0.2262 - binary_accuracy: 0.9069\nEpoch 29: val_loss did not improve from 0.22598\n423/423 [==============================] - 95s 224ms/step - loss: 0.2262 - binary_accuracy: 0.9069 - val_loss: 0.2291 - val_binary_accuracy: 0.9080\nEpoch 30/60\n423/423 [==============================] - ETA: 0s - loss: 0.2241 - binary_accuracy: 0.9077\nEpoch 30: val_loss did not improve from 0.22598\n423/423 [==============================] - 96s 228ms/step - loss: 0.2241 - binary_accuracy: 0.9077 - val_loss: 0.2322 - val_binary_accuracy: 0.9043\nEpoch 31/60\n423/423 [==============================] - ETA: 0s - loss: 0.2239 - binary_accuracy: 0.9082\nEpoch 31: val_loss improved from 0.22598 to 0.22355, saving model to best_val_loss.h5\n423/423 [==============================] - 94s 222ms/step - loss: 0.2239 - binary_accuracy: 0.9082 - val_loss: 0.2235 - val_binary_accuracy: 0.9093\nEpoch 32/60\n423/423 [==============================] - ETA: 0s - loss: 0.2240 - binary_accuracy: 0.9080\nEpoch 32: val_loss did not improve from 0.22355\n423/423 [==============================] - 94s 221ms/step - loss: 0.2240 - binary_accuracy: 0.9080 - val_loss: 0.2321 - val_binary_accuracy: 0.9058\nEpoch 33/60\n423/423 [==============================] - ETA: 0s - loss: 0.2227 - binary_accuracy: 0.9088\nEpoch 33: val_loss did not improve from 0.22355\n423/423 [==============================] - 97s 228ms/step - loss: 0.2227 - binary_accuracy: 0.9088 - val_loss: 0.2264 - val_binary_accuracy: 0.9082\nEpoch 34/60\n423/423 [==============================] - ETA: 0s - loss: 0.2225 - binary_accuracy: 0.9089\nEpoch 34: val_loss did not improve from 0.22355\n423/423 [==============================] - 95s 224ms/step - loss: 0.2225 - binary_accuracy: 0.9089 - val_loss: 0.2275 - val_binary_accuracy: 0.9075\nEpoch 35/60\n423/423 [==============================] - ETA: 0s - loss: 0.2225 - binary_accuracy: 0.9092\nEpoch 35: val_loss did not improve from 0.22355\n423/423 [==============================] - 94s 221ms/step - loss: 0.2225 - binary_accuracy: 0.9092 - val_loss: 0.2252 - val_binary_accuracy: 0.9104\nEpoch 36/60\n423/423 [==============================] - ETA: 0s - loss: 0.2212 - binary_accuracy: 0.9100\nEpoch 37: val_loss did not improve from 0.22355\n423/423 [==============================] - 94s 222ms/step - loss: 0.2212 - binary_accuracy: 0.9100 - val_loss: 0.2287 - val_binary_accuracy: 0.9073\nEpoch 38/60\n423/423 [==============================] - ETA: 0s - loss: 0.2212 - binary_accuracy: 0.9100\nEpoch 38: val_loss did not improve from 0.22355\n423/423 [==============================] - 92s 218ms/step - loss: 0.2212 - binary_accuracy: 0.9100 - val_loss: 0.2262 - val_binary_accuracy: 0.9083\nEpoch 39/60\n423/423 [==============================] - ETA: 0s - loss: 0.2203 - binary_accuracy: 0.9103\nEpoch 39: val_loss did not improve from 0.22355\n423/423 [==============================] - 95s 224ms/step - loss: 0.2203 - binary_accuracy: 0.9103 - val_loss: 0.2333 - val_binary_accuracy: 0.9064\nEpoch 40/60\n423/423 [==============================] - ETA: 0s - loss: 0.2191 - binary_accuracy: 0.9109\nEpoch 40: val_loss did not improve from 0.22355\n423/423 [==============================] - 96s 226ms/step - loss: 0.2191 - binary_accuracy: 0.9109 - val_loss: 0.2251 - val_binary_accuracy: 0.9096\nEpoch 41/60\n423/423 [==============================] - ETA: 0s - loss: 0.2187 - binary_accuracy: 0.9111\nEpoch 41: val_loss did not improve from 0.22355\n423/423 [==============================] - 95s 225ms/step - loss: 0.2187 - binary_accuracy: 0.9111 - val_loss: 0.2286 - val_binary_accuracy: 0.9078\nEpoch 42/60\n423/423 [==============================] - ETA: 0s - loss: 0.2195 - binary_accuracy: 0.9108\nEpoch 42: val_loss did not improve from 0.22355\n423/423 [==============================] - 95s 225ms/step - loss: 0.2195 - binary_accuracy: 0.9108 - val_loss: 0.2269 - val_binary_accuracy: 0.9087\nEpoch 43/60\n125/423 [=======>......................] - ETA: 57s - loss: 0.2186 - binary_accuracy: 0.9111Epoch 44/60\n423/423 [==============================] - ETA: 0s - loss: 0.2178 - binary_accuracy: 0.9119\nEpoch 44: val_loss did not improve from 0.22355\n423/423 [==============================] - 92s 218ms/step - loss: 0.2178 - binary_accuracy: 0.9119 - val_loss: 0.2272 - val_binary_accuracy: 0.9088\nEpoch 45/60\n423/423 [==============================] - ETA: 0s - loss: 0.2180 - binary_accuracy: 0.9116\nEpoch 45: val_loss did not improve from 0.22355\n423/423 [==============================] - 95s 225ms/step - loss: 0.2180 - binary_accuracy: 0.9116 - val_loss: 0.2319 - val_binary_accuracy: 0.9065\nEpoch 46/60\n423/423 [==============================] - ETA: 0s - loss: 0.2185 - binary_accuracy: 0.9116\nEpoch 46: val_loss did not improve from 0.22355\n423/423 [==============================] - 93s 220ms/step - loss: 0.2185 - binary_accuracy: 0.9116 - val_loss: 0.2277 - val_binary_accuracy: 0.9089\nEpoch 47/60\n423/423 [==============================] - ETA: 0s - loss: 0.2177 - binary_accuracy: 0.9121\nEpoch 47: val_loss did not improve from 0.22355\n423/423 [==============================] - 94s 222ms/step - loss: 0.2177 - binary_accuracy: 0.9121 - val_loss: 0.2244 - val_binary_accuracy: 0.9094\nEpoch 48/60\n423/423 [==============================] - ETA: 0s - loss: 0.2175 - binary_accuracy: 0.9122\nEpoch 48: val_loss did not improve from 0.22355\n423/423 [==============================] - 96s 226ms/step - loss: 0.2175 - binary_accuracy: 0.9122 - val_loss: 0.2339 - val_binary_accuracy: 0.9063\nEpoch 49/60\n423/423 [==============================] - ETA: 0s - loss: 0.2173 - binary_accuracy: 0.9124\nEpoch 49: val_loss did not improve from 0.22355\n423/423 [==============================] - 99s 234ms/step - loss: 0.2173 - binary_accuracy: 0.9124 - val_loss: 0.2241 - val_binary_accuracy: 0.9105\nEpoch 50/60\n423/423 [==============================] - ETA: 0s - loss: 0.2173 - binary_accuracy: 0.9126\nEpoch 50: val_loss did not improve from 0.22355\n423/423 [==============================] - 101s 240ms/step - loss: 0.2173 - binary_accuracy: 0.9126 - val_loss: 0.2258 - val_binary_accuracy: 0.9107\nEpoch 51/60\n423/423 [==============================] - ETA: 0s - loss: 0.2156 - binary_accuracy: 0.9130\nEpoch 51: val_loss improved from 0.22355 to 0.22269, saving model to best_val_loss.h5\n423/423 [==============================] - 104s 246ms/step - loss: 0.2156 - binary_accuracy: 0.9130 - val_loss: 0.2227 - val_binary_accuracy: 0.9106\nEpoch 52/60\n423/423 [==============================] - ETA: 0s - loss: 0.2152 - binary_accuracy: 0.9136\nEpoch 52: val_loss did not improve from 0.22269\n423/423 [==============================] - 107s 252ms/step - loss: 0.2152 - binary_accuracy: 0.9136 - val_loss: 0.2261 - val_binary_accuracy: 0.9100\nEpoch 53/60\n423/423 [==============================] - ETA: 0s - loss: 0.2153 - binary_accuracy: 0.9136\nEpoch 53: val_loss did not improve from 0.22269\n423/423 [==============================] - 106s 251ms/step - loss: 0.2153 - binary_accuracy: 0.9136 - val_loss: 0.2301 - val_binary_accuracy: 0.9084\nEpoch 54/60\n423/423 [==============================] - ETA: 0s - loss: 0.2145 - binary_accuracy: 0.9138\nEpoch 54: val_loss did not improve from 0.22269\n423/423 [==============================] - 105s 249ms/step - loss: 0.2145 - binary_accuracy: 0.9138 - val_loss: 0.2258 - val_binary_accuracy: 0.9106\nEpoch 55/60\n423/423 [==============================] - ETA: 0s - loss: 0.2145 - binary_accuracy: 0.9144\nEpoch 55: val_loss did not improve from 0.22269\n423/423 [==============================] - 104s 246ms/step - loss: 0.2145 - binary_accuracy: 0.9144 - val_loss: 0.2270 - val_binary_accuracy: 0.9098\nEpoch 56/60\n423/423 [==============================] - ETA: 0s - loss: 0.2140 - binary_accuracy: 0.9144\nEpoch 56: val_loss did not improve from 0.22269\n423/423 [==============================] - 105s 249ms/step - loss: 0.2140 - binary_accuracy: 0.9144 - val_loss: 0.2255 - val_binary_accuracy: 0.9098\nEpoch 57/60\n423/423 [==============================] - ETA: 0s - loss: 0.2149 - binary_accuracy: 0.9141\nEpoch 57: val_loss did not improve from 0.22269\n423/423 [==============================] - 106s 249ms/step - loss: 0.2149 - binary_accuracy: 0.9141 - val_loss: 0.2322 - val_binary_accuracy: 0.9078\nEpoch 58/60\n423/423 [==============================] - ETA: 0s - loss: 0.2134 - binary_accuracy: 0.9147\nEpoch 58: val_loss did not improve from 0.22269\n423/423 [==============================] - 103s 243ms/step - loss: 0.2134 - binary_accuracy: 0.9147 - val_loss: 0.2248 - val_binary_accuracy: 0.9105\nEpoch 59/60\n423/423 [==============================] - ETA: 0s - loss: 0.2142 - binary_accuracy: 0.9145\nEpoch 59: val_loss did not improve from 0.22269\n423/423 [==============================] - 101s 239ms/step - loss: 0.2142 - binary_accuracy: 0.9145 - val_loss: 0.2287 - val_binary_accuracy: 0.9085\nEpoch 60/60\n423/423 [==============================] - ETA: 0s - loss: 0.2131 - binary_accuracy: 0.9149\nEpoch 60: val_loss did not improve from 0.22269\n423/423 [==============================] - 98s 232ms/step - loss: 0.2131 - binary_accuracy: 0.9149 - val_loss: 0.2314 - val_binary_accuracy: 0.9091\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x79719bd335b0>"},"metadata":{}}]},{"cell_type":"code","source":"experiment.log_model(\"Facial_r\", filepath)\nexperiment.end()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T08:18:18.751734Z","iopub.execute_input":"2023-11-25T08:18:18.752666Z","iopub.status.idle":"2023-11-25T08:18:22.861506Z","shell.execute_reply.started":"2023-11-25T08:18:18.752625Z","shell.execute_reply":"2023-11-25T08:18:22.860697Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/gurumasterahb/regularizer/43be4131cd8641718803b2160871e5cb\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_binary_accuracy [2580]         : (0.4609375, 0.9268091917037964)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_loss [2580]                    : (0.19610679149627686, 0.8063083291053772)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     binary_accuracy [60]                 : (0.8090057969093323, 0.9148674011230469)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch_duration [60]                  : (91.45809784200083, 281.05137145599997)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [60]                            : (0.21310879290103912, 0.522043764591217)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_binary_accuracy [60]             : (0.8274397253990173, 0.9107329249382019)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_loss [60]                        : (0.22269240021705627, 0.4554537534713745)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validate_batch_binary_accuracy [360] : (0.8264802694320679, 0.9198191165924072)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validate_batch_loss [360]            : (0.1997072845697403, 0.45804813504219055)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name             : Try_6 [from: FunctionalAPI]\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainable_params : 5018086\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Optimizer                       : RMSprop\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_centered                : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_clipnorm                : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_clipvalue               : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_ema_momentum            : 0.99\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_ema_overwrite_frequency : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_epsilon                 : 1e-07\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_global_clipnorm         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_is_legacy_optimizer     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_jit_compile             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_learning_rate           : 0.0010000000474974513\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_momentum                : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_name                    : RMSprop\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_rho                     : 0.9\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_use_ema                 : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_weight_decay            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size                      : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs                          : 60\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss                            : binary_crossentropy\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_class                       : 38\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_test                        : 19962\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train                       : 162770\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_val                         : 19867\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer                       : RMSprop\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     steps                           : 423\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     histogram3d                  : 1586\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element                : 1 (38.38 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 4.92 MB/38.38 MB\n","output_type":"stream"}]}]}