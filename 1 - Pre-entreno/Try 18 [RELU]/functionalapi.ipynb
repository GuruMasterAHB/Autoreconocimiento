{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7028419,"sourceType":"datasetVersion","datasetId":4042417}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# Para llevar el registro\n!pip install -q comet_ml\nimport comet_ml\ncomet_ml.init(project_name = 'Regularizer')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:15:14.179425Z","iopub.execute_input":"2023-11-25T01:15:14.179732Z","iopub.status.idle":"2023-11-25T01:15:47.749761Z","shell.execute_reply.started":"2023-11-25T01:15:14.179704Z","shell.execute_reply":"2023-11-25T01:15:47.748729Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mPlease paste your Comet API key from https://www.comet.com/api/my/settings/\n(api key may not show as you type)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Comet API key:  ·························\n"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Conv2D, MaxPooling2D, Concatenate\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adadelta\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.regularizers import l2","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:15:47.751321Z","iopub.execute_input":"2023-11-25T01:15:47.751644Z","iopub.status.idle":"2023-11-25T01:15:59.689013Z","shell.execute_reply.started":"2023-11-25T01:15:47.751617Z","shell.execute_reply":"2023-11-25T01:15:59.687870Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Se crea el experimento en Comet\nexperiment = comet_ml.Experiment(\n    auto_histogram_weight_logging = True,\n    auto_histogram_gradient_logging = True,\n    auto_histogram_activation_logging = True,\n    log_code = True\n)\nexperiment.set_name('Try_5 [from: FunctionalAPI]')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:15:59.690279Z","iopub.execute_input":"2023-11-25T01:15:59.690846Z","iopub.status.idle":"2023-11-25T01:16:03.266652Z","shell.execute_reply.started":"2023-11-25T01:15:59.690798Z","shell.execute_reply":"2023-11-25T01:16:03.265511Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/gurumasterahb/regularizer/60981e5d06944e77aa46274cff0a6293\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cargar los datos de los txt\nfile_attr = os.path.join('/kaggle/input/img-align-celeba-partition/attr.csv')\nattr = pd.read_csv(file_attr)\n\n# Imágenes\ni_test = '/kaggle/input/img-align-celeba-partition/align_partition/align_test'\ni_train = '/kaggle/input/img-align-celeba-partition/align_partition/align_train'\ni_val = '/kaggle/input/img-align-celeba-partition/align_partition/align_val'","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:16:03.270155Z","iopub.execute_input":"2023-11-25T01:16:03.270545Z","iopub.status.idle":"2023-11-25T01:16:04.194673Z","shell.execute_reply.started":"2023-11-25T01:16:03.270508Z","shell.execute_reply":"2023-11-25T01:16:04.193690Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Parámetros\ni_width = int(178 * 1.2)\ni_height = int(218 * 1.2)\ninput_shape = (i_width, i_height, 3)\n\nparameters = {\n    'num_class' : 38,\n    'epochs' : 60,\n    'batch_size' : 64,\n    'loss' : 'binary_crossentropy',\n    'optimizer' : 'RMSprop',\n    'num_train' : 162770,\n    'num_val' : 19867,\n    'num_test' : 19962,\n}\nexperiment.log_parameters(parameters)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:16:04.197879Z","iopub.execute_input":"2023-11-25T01:16:04.198297Z","iopub.status.idle":"2023-11-25T01:16:04.233609Z","shell.execute_reply.started":"2023-11-25T01:16:04.198262Z","shell.execute_reply":"2023-11-25T01:16:04.232615Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Solo toma el entero\nepoch_steps = parameters['num_train'] // (parameters['batch_size'] * 6) # Training\nval_steps = parameters['num_val'] // (parameters['batch_size'] * 6) # Validation\ntest_steps = parameters['num_test'] // (parameters['batch_size'] * 6) # Testing","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:16:04.235058Z","iopub.execute_input":"2023-11-25T01:16:04.235454Z","iopub.status.idle":"2023-11-25T01:16:04.247806Z","shell.execute_reply.started":"2023-11-25T01:16:04.235408Z","shell.execute_reply":"2023-11-25T01:16:04.246851Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"gen_train = ImageDataGenerator(rescale = 1./255.)\ntrain = gen_train.flow_from_dataframe(\n    attr,\n    directory = i_train,\n    x_col = attr.columns[0],  # Nombre de la columna que contiene los nombres de las imágenes\n    y_col = attr.columns[1:],  # Lista de nombres de las columnas de atributos\n    target_size = (i_width, i_height),\n    batch_size = parameters['batch_size'],\n    class_mode = 'raw',\n    shuffle = True\n)\n\ngen_val = ImageDataGenerator(rescale = 1./255.)\nval = gen_val.flow_from_dataframe(\n    attr,\n    directory = i_val,\n    x_col = attr.columns[0],  # Nombre de la columna que contiene los nombres de las imágenes\n    y_col = attr.columns[1:],  # Lista de nombres de las columnas de atributos\n    target_size = (i_width, i_height),\n    batch_size = parameters['batch_size'],\n    class_mode = 'raw',\n    shuffle = True\n)\n\ngen_testing = ImageDataGenerator(rescale = 1./255.)\ntest = gen_testing.flow_from_dataframe(\n    attr,\n    directory = i_test,\n    x_col = attr.columns[0],  # Nombre de la columna que contiene los nombres de las imágenes\n    y_col = attr.columns[1:],  # Lista de nombres de las columnas de atributos\n    target_size = (i_width, i_height),\n    batch_size = parameters['batch_size'],\n    class_mode = 'raw',\n    shuffle = True\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:16:04.249197Z","iopub.execute_input":"2023-11-25T01:16:04.250058Z","iopub.status.idle":"2023-11-25T01:31:03.226681Z","shell.execute_reply.started":"2023-11-25T01:16:04.250025Z","shell.execute_reply":"2023-11-25T01:31:03.225860Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 162770 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 39829 invalid image filename(s) in x_col=\"202599\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 19867 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 182732 invalid image filename(s) in x_col=\"202599\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 19962 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 182637 invalid image filename(s) in x_col=\"202599\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Arquitectura\n# Functional API\ninputs = Input(shape = input_shape)\n\nconv1 = Conv2D(32, (3,3), activation = 'relu')(inputs)\nmpool1 = MaxPooling2D(pool_size = (2,2))(conv1)\n\nconv2 = Conv2D(64, (3,3), activation = 'relu', kernel_regularizer = l2(0.0001))(mpool1)\nmpool2 = MaxPooling2D(pool_size = (2,2))(conv2)\n\nconv3 = Conv2D(128, (3,3), activation = 'relu')(mpool2)\nmpool3 = MaxPooling2D(pool_size = (2,2))(conv3)\n\nconv4 = Conv2D(256, (3,3), activation = 'relu')(mpool3)\nmpool4 = MaxPooling2D(pool_size = (2,2))(conv4)\n\nconv5 = Conv2D(512, (3,3), activation = 'relu', kernel_regularizer = l2(0.0001))(mpool4)\nmpool5 = MaxPooling2D(pool_size = (2,2))(conv5)\n\nconv6 = Conv2D(256, (3,3), activation = 'relu')(mpool5)\nmpool6 = MaxPooling2D(pool_size = (2,2))(conv6)\n\nx = Flatten()(mpool6)\n\nx_1 = Dense(512, activation = 'relu')(x)\nx_2 = Dense(512, activation = 'relu')(x)\n\nx = Concatenate()([x_1, x_2])\n\nx = Dense(1024, activation = 'relu')(x)\nx = Dropout(0.15)(x)\n\nx = Dense(512, activation = 'PReLU', kernel_regularizer = l2(0.0001))(x)\n\nx = Dense(256, activation = 'PReLU')(x)\n\nx = Dense(128, activation = 'relu')(x)\n\nX = Dense(parameters['num_class'], activation = 'sigmoid')(x)\n\nmodel = tf.keras.Model(inputs = inputs, outputs = X)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:31:03.228129Z","iopub.execute_input":"2023-11-25T01:31:03.228468Z","iopub.status.idle":"2023-11-25T01:31:06.492847Z","shell.execute_reply.started":"2023-11-25T01:31:03.228434Z","shell.execute_reply":"2023-11-25T01:31:06.491822Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 213, 261, 3)]        0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 211, 259, 32)         896       ['input_1[0][0]']             \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 105, 129, 32)         0         ['conv2d[0][0]']              \n D)                                                                                               \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 103, 127, 64)         18496     ['max_pooling2d[0][0]']       \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 51, 63, 64)           0         ['conv2d_1[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 49, 61, 128)          73856     ['max_pooling2d_1[0][0]']     \n                                                                                                  \n max_pooling2d_2 (MaxPoolin  (None, 24, 30, 128)          0         ['conv2d_2[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 22, 28, 256)          295168    ['max_pooling2d_2[0][0]']     \n                                                                                                  \n max_pooling2d_3 (MaxPoolin  (None, 11, 14, 256)          0         ['conv2d_3[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 9, 12, 512)           1180160   ['max_pooling2d_3[0][0]']     \n                                                                                                  \n max_pooling2d_4 (MaxPoolin  (None, 4, 6, 512)            0         ['conv2d_4[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 2, 4, 256)            1179904   ['max_pooling2d_4[0][0]']     \n                                                                                                  \n max_pooling2d_5 (MaxPoolin  (None, 1, 2, 256)            0         ['conv2d_5[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n flatten (Flatten)           (None, 512)                  0         ['max_pooling2d_5[0][0]']     \n                                                                                                  \n dense (Dense)               (None, 512)                  262656    ['flatten[0][0]']             \n                                                                                                  \n dense_1 (Dense)             (None, 512)                  262656    ['flatten[0][0]']             \n                                                                                                  \n concatenate (Concatenate)   (None, 1024)                 0         ['dense[0][0]',               \n                                                                     'dense_1[0][0]']             \n                                                                                                  \n dense_2 (Dense)             (None, 1024)                 1049600   ['concatenate[0][0]']         \n                                                                                                  \n dropout (Dropout)           (None, 1024)                 0         ['dense_2[0][0]']             \n                                                                                                  \n dense_3 (Dense)             (None, 512)                  525312    ['dropout[0][0]']             \n                                                                                                  \n dense_4 (Dense)             (None, 256)                  131584    ['dense_3[0][0]']             \n                                                                                                  \n dense_5 (Dense)             (None, 128)                  32896     ['dense_4[0][0]']             \n                                                                                                  \n dense_6 (Dense)             (None, 38)                   4902      ['dense_5[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 5018086 (19.14 MB)\nTrainable params: 5018086 (19.14 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Checkpoint para el mejor modelo (val_accuracy)\nfilepath = 'best_val_loss.h5'\ncheckpoint = ModelCheckpoint(\n    filepath,\n    monitor = 'val_loss',\n    verbose = 1,\n    save_best_only = True,\n    mode = 'min'\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:31:06.494439Z","iopub.execute_input":"2023-11-25T01:31:06.495359Z","iopub.status.idle":"2023-11-25T01:31:06.501089Z","shell.execute_reply.started":"2023-11-25T01:31:06.495318Z","shell.execute_reply":"2023-11-25T01:31:06.499931Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Compilación y entrenamiento\nmodel.compile(\n    loss = parameters['loss'],\n    optimizer = RMSprop(learning_rate = 0.001),\n    metrics = ['binary_accuracy']\n)\n\nmodel.fit(\n    train,\n    batch_size = parameters['batch_size'],\n    epochs = parameters['epochs'],\n    verbose = 1,\n    validation_data = val,\n    steps_per_epoch = epoch_steps,\n    validation_steps = val_steps,\n    callbacks = [checkpoint]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T01:31:06.504737Z","iopub.execute_input":"2023-11-25T01:31:06.505165Z","iopub.status.idle":"2023-11-25T03:25:24.954904Z","shell.execute_reply.started":"2023-11-25T01:31:06.505127Z","shell.execute_reply":"2023-11-25T03:25:24.953814Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m auto_histogram_gradient_logging is True, but inputs and targets are not available; unable to log gradients\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m auto_histogram_activation_logging is True, but inputs are not available; unable to log activations\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/60\n423/423 [==============================] - ETA: 0s - loss: 0.5218 - binary_accuracy: 0.8078\nEpoch 1: val_loss improved from inf to 0.47354, saving model to best_val_loss.h5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"423/423 [==============================] - 263s 591ms/step - loss: 0.5218 - binary_accuracy: 0.8078 - val_loss: 0.4735 - val_binary_accuracy: 0.8180\nEpoch 2/60\n423/423 [==============================] - ETA: 0s - loss: 0.4177 - binary_accuracy: 0.8379\nEpoch 2: val_loss improved from 0.47354 to 0.37642, saving model to best_val_loss.h5\n423/423 [==============================] - 225s 531ms/step - loss: 0.4177 - binary_accuracy: 0.8379 - val_loss: 0.3764 - val_binary_accuracy: 0.8536\nEpoch 3/60\n423/423 [==============================] - ETA: 0s - loss: 0.3547 - binary_accuracy: 0.8608\nEpoch 3: val_loss improved from 0.37642 to 0.32738, saving model to best_val_loss.h5\n423/423 [==============================] - 203s 480ms/step - loss: 0.3547 - binary_accuracy: 0.8608 - val_loss: 0.3274 - val_binary_accuracy: 0.8693\nEpoch 4/60\n423/423 [==============================] - ETA: 0s - loss: 0.3210 - binary_accuracy: 0.8698\nEpoch 4: val_loss improved from 0.32738 to 0.30464, saving model to best_val_loss.h5\n423/423 [==============================] - 185s 436ms/step - loss: 0.3210 - binary_accuracy: 0.8698 - val_loss: 0.3046 - val_binary_accuracy: 0.8785\nEpoch 5/60\n423/423 [==============================] - ETA: 0s - loss: 0.2995 - binary_accuracy: 0.8759\nEpoch 5: val_loss improved from 0.30464 to 0.28289, saving model to best_val_loss.h5\n423/423 [==============================] - 171s 405ms/step - loss: 0.2995 - binary_accuracy: 0.8759 - val_loss: 0.2829 - val_binary_accuracy: 0.8831\nEpoch 6/60\n423/423 [==============================] - ETA: 0s - loss: 0.2860 - binary_accuracy: 0.8808\nEpoch 6: val_loss improved from 0.28289 to 0.28212, saving model to best_val_loss.h5\n423/423 [==============================] - 161s 379ms/step - loss: 0.2860 - binary_accuracy: 0.8808 - val_loss: 0.2821 - val_binary_accuracy: 0.8815\nEpoch 7/60\n423/423 [==============================] - ETA: 0s - loss: 0.2752 - binary_accuracy: 0.8843\nEpoch 7: val_loss improved from 0.28212 to 0.26828, saving model to best_val_loss.h5\n423/423 [==============================] - 153s 360ms/step - loss: 0.2752 - binary_accuracy: 0.8843 - val_loss: 0.2683 - val_binary_accuracy: 0.8891\nEpoch 8/60\n423/423 [==============================] - ETA: 0s - loss: 0.2663 - binary_accuracy: 0.8876\nEpoch 8: val_loss did not improve from 0.26828\n423/423 [==============================] - 139s 328ms/step - loss: 0.2663 - binary_accuracy: 0.8876 - val_loss: 0.2769 - val_binary_accuracy: 0.8841\nEpoch 9/60\n423/423 [==============================] - ETA: 0s - loss: 0.2601 - binary_accuracy: 0.8903\nEpoch 9: val_loss improved from 0.26828 to 0.25556, saving model to best_val_loss.h5\n423/423 [==============================] - 131s 310ms/step - loss: 0.2601 - binary_accuracy: 0.8903 - val_loss: 0.2556 - val_binary_accuracy: 0.8938\nEpoch 10/60\n423/423 [==============================] - ETA: 0s - loss: 0.2544 - binary_accuracy: 0.8930\nEpoch 10: val_loss improved from 0.25556 to 0.25549, saving model to best_val_loss.h5\n423/423 [==============================] - 123s 291ms/step - loss: 0.2544 - binary_accuracy: 0.8930 - val_loss: 0.2555 - val_binary_accuracy: 0.8926\nEpoch 11/60\n423/423 [==============================] - ETA: 0s - loss: 0.2515 - binary_accuracy: 0.8938\nEpoch 11: val_loss improved from 0.25549 to 0.24791, saving model to best_val_loss.h5\n423/423 [==============================] - 119s 281ms/step - loss: 0.2515 - binary_accuracy: 0.8938 - val_loss: 0.2479 - val_binary_accuracy: 0.8965\nEpoch 12/60\n423/423 [==============================] - ETA: 0s - loss: 0.2478 - binary_accuracy: 0.8960\nEpoch 12: val_loss improved from 0.24791 to 0.24136, saving model to best_val_loss.h5\n423/423 [==============================] - 112s 265ms/step - loss: 0.2478 - binary_accuracy: 0.8960 - val_loss: 0.2414 - val_binary_accuracy: 0.9003\nEpoch 13/60\n423/423 [==============================] - ETA: 0s - loss: 0.2447 - binary_accuracy: 0.8975\nEpoch 13: val_loss did not improve from 0.24136\n423/423 [==============================] - 109s 257ms/step - loss: 0.2447 - binary_accuracy: 0.8975 - val_loss: 0.2440 - val_binary_accuracy: 0.8984\nEpoch 14/60\n423/423 [==============================] - ETA: 0s - loss: 0.2422 - binary_accuracy: 0.8985\nEpoch 14: val_loss improved from 0.24136 to 0.23423, saving model to best_val_loss.h5\n423/423 [==============================] - 105s 249ms/step - loss: 0.2422 - binary_accuracy: 0.8985 - val_loss: 0.2342 - val_binary_accuracy: 0.9038\nEpoch 15/60\n423/423 [==============================] - ETA: 0s - loss: 0.2401 - binary_accuracy: 0.8996\nEpoch 15: val_loss improved from 0.23423 to 0.23320, saving model to best_val_loss.h5\n423/423 [==============================] - 103s 244ms/step - loss: 0.2401 - binary_accuracy: 0.8996 - val_loss: 0.2332 - val_binary_accuracy: 0.9037\nEpoch 16/60\n423/423 [==============================] - ETA: 0s - loss: 0.2385 - binary_accuracy: 0.9005\nEpoch 16: val_loss did not improve from 0.23320\n423/423 [==============================] - 100s 236ms/step - loss: 0.2385 - binary_accuracy: 0.9005 - val_loss: 0.2441 - val_binary_accuracy: 0.8996\nEpoch 17/60\n423/423 [==============================] - ETA: 0s - loss: 0.2370 - binary_accuracy: 0.9015\nEpoch 17: val_loss did not improve from 0.23320\n423/423 [==============================] - 97s 230ms/step - loss: 0.2370 - binary_accuracy: 0.9015 - val_loss: 0.2390 - val_binary_accuracy: 0.9012\nEpoch 18/60\n423/423 [==============================] - ETA: 0s - loss: 0.2346 - binary_accuracy: 0.9025\nEpoch 18: val_loss did not improve from 0.23320\n423/423 [==============================] - 95s 224ms/step - loss: 0.2346 - binary_accuracy: 0.9025 - val_loss: 0.2363 - val_binary_accuracy: 0.9020\nEpoch 19/60\n423/423 [==============================] - ETA: 0s - loss: 0.2340 - binary_accuracy: 0.9027\nEpoch 19: val_loss improved from 0.23320 to 0.23097, saving model to best_val_loss.h5\n423/423 [==============================] - 96s 226ms/step - loss: 0.2340 - binary_accuracy: 0.9027 - val_loss: 0.2310 - val_binary_accuracy: 0.9048\nEpoch 20/60\n423/423 [==============================] - ETA: 0s - loss: 0.2327 - binary_accuracy: 0.9034\nEpoch 20: val_loss did not improve from 0.23097\n423/423 [==============================] - 94s 222ms/step - loss: 0.2327 - binary_accuracy: 0.9034 - val_loss: 0.2312 - val_binary_accuracy: 0.9061\nEpoch 21/60\n423/423 [==============================] - ETA: 0s - loss: 0.2313 - binary_accuracy: 0.9043\nEpoch 21: val_loss did not improve from 0.23097\n423/423 [==============================] - 94s 222ms/step - loss: 0.2313 - binary_accuracy: 0.9043 - val_loss: 0.2342 - val_binary_accuracy: 0.9039\nEpoch 22/60\n423/423 [==============================] - ETA: 0s - loss: 0.2307 - binary_accuracy: 0.9047\nEpoch 22: val_loss improved from 0.23097 to 0.22347, saving model to best_val_loss.h5\n423/423 [==============================] - 95s 224ms/step - loss: 0.2307 - binary_accuracy: 0.9047 - val_loss: 0.2235 - val_binary_accuracy: 0.9088\nEpoch 23/60\n423/423 [==============================] - ETA: 0s - loss: 0.2297 - binary_accuracy: 0.9051\nEpoch 23: val_loss did not improve from 0.22347\n423/423 [==============================] - 96s 226ms/step - loss: 0.2297 - binary_accuracy: 0.9051 - val_loss: 0.2352 - val_binary_accuracy: 0.9042\nEpoch 24/60\n423/423 [==============================] - ETA: 0s - loss: 0.2273 - binary_accuracy: 0.9063\nEpoch 24: val_loss did not improve from 0.22347\n423/423 [==============================] - 91s 215ms/step - loss: 0.2273 - binary_accuracy: 0.9063 - val_loss: 0.2331 - val_binary_accuracy: 0.9043\nEpoch 25/60\n423/423 [==============================] - ETA: 0s - loss: 0.2263 - binary_accuracy: 0.9068\nEpoch 26: val_loss did not improve from 0.22347\n423/423 [==============================] - 90s 214ms/step - loss: 0.2263 - binary_accuracy: 0.9068 - val_loss: 0.2297 - val_binary_accuracy: 0.9068\nEpoch 27/60\n423/423 [==============================] - ETA: 0s - loss: 0.2261 - binary_accuracy: 0.9067\nEpoch 27: val_loss did not improve from 0.22347\n423/423 [==============================] - 90s 213ms/step - loss: 0.2261 - binary_accuracy: 0.9067 - val_loss: 0.2289 - val_binary_accuracy: 0.9068\nEpoch 28/60\n423/423 [==============================] - ETA: 0s - loss: 0.2255 - binary_accuracy: 0.9072\nEpoch 28: val_loss did not improve from 0.22347\n423/423 [==============================] - 91s 215ms/step - loss: 0.2255 - binary_accuracy: 0.9072 - val_loss: 0.2314 - val_binary_accuracy: 0.9054\nEpoch 29/60\n423/423 [==============================] - ETA: 0s - loss: 0.2252 - binary_accuracy: 0.9077\nEpoch 29: val_loss did not improve from 0.22347\n423/423 [==============================] - 90s 212ms/step - loss: 0.2252 - binary_accuracy: 0.9077 - val_loss: 0.2285 - val_binary_accuracy: 0.9058\nEpoch 30/60\n423/423 [==============================] - ETA: 0s - loss: 0.2239 - binary_accuracy: 0.9085\nEpoch 30: val_loss did not improve from 0.22347\n423/423 [==============================] - 90s 212ms/step - loss: 0.2239 - binary_accuracy: 0.9085 - val_loss: 0.2290 - val_binary_accuracy: 0.9074\nEpoch 31/60\n423/423 [==============================] - ETA: 0s - loss: 0.2234 - binary_accuracy: 0.9087\nEpoch 31: val_loss improved from 0.22347 to 0.22279, saving model to best_val_loss.h5\n423/423 [==============================] - 88s 208ms/step - loss: 0.2234 - binary_accuracy: 0.9087 - val_loss: 0.2228 - val_binary_accuracy: 0.9101\nEpoch 32/60\n423/423 [==============================] - ETA: 0s - loss: 0.2227 - binary_accuracy: 0.9088\nEpoch 32: val_loss did not improve from 0.22279\n423/423 [==============================] - 89s 211ms/step - loss: 0.2227 - binary_accuracy: 0.9088 - val_loss: 0.2294 - val_binary_accuracy: 0.9081\nEpoch 33/60\n423/423 [==============================] - ETA: 0s - loss: 0.2210 - binary_accuracy: 0.9096\nEpoch 33: val_loss did not improve from 0.22279\n423/423 [==============================] - 88s 208ms/step - loss: 0.2210 - binary_accuracy: 0.9096 - val_loss: 0.2296 - val_binary_accuracy: 0.9070\nEpoch 34/60\n423/423 [==============================] - ETA: 0s - loss: 0.2207 - binary_accuracy: 0.9097\nEpoch 34: val_loss did not improve from 0.22279\n423/423 [==============================] - 91s 214ms/step - loss: 0.2207 - binary_accuracy: 0.9097 - val_loss: 0.2234 - val_binary_accuracy: 0.9101\nEpoch 35/60\n423/423 [==============================] - ETA: 0s - loss: 0.2210 - binary_accuracy: 0.9100\nEpoch 35: val_loss did not improve from 0.22279\n423/423 [==============================] - 91s 214ms/step - loss: 0.2210 - binary_accuracy: 0.9100 - val_loss: 0.2271 - val_binary_accuracy: 0.9091\nEpoch 36/60\n423/423 [==============================] - ETA: 0s - loss: 0.2205 - binary_accuracy: 0.9101\nEpoch 36: val_loss did not improve from 0.22279\n423/423 [==============================] - 90s 213ms/step - loss: 0.2205 - binary_accuracy: 0.9101 - val_loss: 0.2242 - val_binary_accuracy: 0.9106\nEpoch 37/60\n423/423 [==============================] - ETA: 0s - loss: 0.2198 - binary_accuracy: 0.9107\nEpoch 37: val_loss did not improve from 0.22279\n423/423 [==============================] - 89s 211ms/step - loss: 0.2198 - binary_accuracy: 0.9107 - val_loss: 0.2286 - val_binary_accuracy: 0.9073\nEpoch 38/60\n423/423 [==============================] - ETA: 0s - loss: 0.2198 - binary_accuracy: 0.9106\nEpoch 38: val_loss did not improve from 0.22279\n423/423 [==============================] - 91s 214ms/step - loss: 0.2198 - binary_accuracy: 0.9106 - val_loss: 0.2248 - val_binary_accuracy: 0.9099\nEpoch 39/60\n423/423 [==============================] - ETA: 0s - loss: 0.2191 - binary_accuracy: 0.9109\nEpoch 39: val_loss did not improve from 0.22279\n423/423 [==============================] - 89s 211ms/step - loss: 0.2191 - binary_accuracy: 0.9109 - val_loss: 0.2262 - val_binary_accuracy: 0.9096\nEpoch 40/60\n423/423 [==============================] - ETA: 0s - loss: 0.2177 - binary_accuracy: 0.9117\nEpoch 40: val_loss did not improve from 0.22279\n423/423 [==============================] - 90s 214ms/step - loss: 0.2177 - binary_accuracy: 0.9117 - val_loss: 0.2253 - val_binary_accuracy: 0.9095\nEpoch 41/60\n423/423 [==============================] - ETA: 0s - loss: 0.2176 - binary_accuracy: 0.9120\nEpoch 41: val_loss did not improve from 0.22279\n423/423 [==============================] - 92s 217ms/step - loss: 0.2176 - binary_accuracy: 0.9120 - val_loss: 0.2282 - val_binary_accuracy: 0.9083\nEpoch 42/60\n423/423 [==============================] - ETA: 0s - loss: 0.2174 - binary_accuracy: 0.9118\nEpoch 42: val_loss did not improve from 0.22279\n423/423 [==============================] - 92s 218ms/step - loss: 0.2174 - binary_accuracy: 0.9118 - val_loss: 0.2252 - val_binary_accuracy: 0.9096\nEpoch 43/60\n423/423 [==============================] - ETA: 0s - loss: 0.2163 - binary_accuracy: 0.9127\nEpoch 43: val_loss did not improve from 0.22279\n423/423 [==============================] - 88s 209ms/step - loss: 0.2163 - binary_accuracy: 0.9127 - val_loss: 0.2297 - val_binary_accuracy: 0.9086\nEpoch 44/60\n423/423 [==============================] - ETA: 0s - loss: 0.2165 - binary_accuracy: 0.9126\nEpoch 44: val_loss did not improve from 0.22279\n423/423 [==============================] - 90s 212ms/step - loss: 0.2165 - binary_accuracy: 0.9126 - val_loss: 0.2291 - val_binary_accuracy: 0.9090\nEpoch 45/60\n423/423 [==============================] - ETA: 0s - loss: 0.2165 - binary_accuracy: 0.9124\nEpoch 45: val_loss did not improve from 0.22279\n423/423 [==============================] - 92s 217ms/step - loss: 0.2165 - binary_accuracy: 0.9124 - val_loss: 0.2283 - val_binary_accuracy: 0.9086\nEpoch 46/60\n423/423 [==============================] - ETA: 0s - loss: 0.2152 - binary_accuracy: 0.9133\nEpoch 46: val_loss did not improve from 0.22279\n423/423 [==============================] - 97s 228ms/step - loss: 0.2152 - binary_accuracy: 0.9133 - val_loss: 0.2279 - val_binary_accuracy: 0.9091\nEpoch 47/60\n423/423 [==============================] - ETA: 0s - loss: 0.2162 - binary_accuracy: 0.9129\nEpoch 47: val_loss improved from 0.22279 to 0.22213, saving model to best_val_loss.h5\n423/423 [==============================] - 101s 239ms/step - loss: 0.2162 - binary_accuracy: 0.9129 - val_loss: 0.2221 - val_binary_accuracy: 0.9116\nEpoch 48/60\n423/423 [==============================] - ETA: 0s - loss: 0.2159 - binary_accuracy: 0.9130\nEpoch 48: val_loss improved from 0.22213 to 0.22198, saving model to best_val_loss.h5\n423/423 [==============================] - 99s 235ms/step - loss: 0.2159 - binary_accuracy: 0.9130 - val_loss: 0.2220 - val_binary_accuracy: 0.9116\nEpoch 49/60\n423/423 [==============================] - ETA: 0s - loss: 0.2160 - binary_accuracy: 0.9130\nEpoch 49: val_loss did not improve from 0.22198\n423/423 [==============================] - 99s 234ms/step - loss: 0.2160 - binary_accuracy: 0.9130 - val_loss: 0.2375 - val_binary_accuracy: 0.9054\nEpoch 50/60\n423/423 [==============================] - ETA: 0s - loss: 0.2143 - binary_accuracy: 0.9137\nEpoch 50: val_loss did not improve from 0.22198\n423/423 [==============================] - 102s 240ms/step - loss: 0.2143 - binary_accuracy: 0.9137 - val_loss: 0.2248 - val_binary_accuracy: 0.9109\nEpoch 51/60\n423/423 [==============================] - ETA: 0s - loss: 0.2141 - binary_accuracy: 0.9139\nEpoch 51: val_loss did not improve from 0.22198\n423/423 [==============================] - 102s 241ms/step - loss: 0.2141 - binary_accuracy: 0.9139 - val_loss: 0.2293 - val_binary_accuracy: 0.9081\nEpoch 52/60\n423/423 [==============================] - ETA: 0s - loss: 0.2140 - binary_accuracy: 0.9140\nEpoch 52: val_loss did not improve from 0.22198\n423/423 [==============================] - 101s 240ms/step - loss: 0.2140 - binary_accuracy: 0.9140 - val_loss: 0.2266 - val_binary_accuracy: 0.9100\nEpoch 53/60\n423/423 [==============================] - ETA: 0s - loss: 0.2137 - binary_accuracy: 0.9139\nEpoch 53: val_loss did not improve from 0.22198\n423/423 [==============================] - 109s 258ms/step - loss: 0.2137 - binary_accuracy: 0.9139 - val_loss: 0.2255 - val_binary_accuracy: 0.9096\nEpoch 54/60\n423/423 [==============================] - ETA: 0s - loss: 0.2136 - binary_accuracy: 0.9145\nEpoch 54: val_loss did not improve from 0.22198\n423/423 [==============================] - 103s 243ms/step - loss: 0.2136 - binary_accuracy: 0.9145 - val_loss: 0.2266 - val_binary_accuracy: 0.9104\nEpoch 55/60\n423/423 [==============================] - ETA: 0s - loss: 0.2136 - binary_accuracy: 0.9144\nEpoch 55: val_loss did not improve from 0.22198\n423/423 [==============================] - 97s 230ms/step - loss: 0.2136 - binary_accuracy: 0.9144 - val_loss: 0.2239 - val_binary_accuracy: 0.9114\nEpoch 56/60\n423/423 [==============================] - ETA: 0s - loss: 0.2133 - binary_accuracy: 0.9146\nEpoch 56: val_loss did not improve from 0.22198\n423/423 [==============================] - 97s 230ms/step - loss: 0.2133 - binary_accuracy: 0.9146 - val_loss: 0.2244 - val_binary_accuracy: 0.9113\nEpoch 57/60\n423/423 [==============================] - ETA: 0s - loss: 0.2122 - binary_accuracy: 0.9152\nEpoch 57: val_loss did not improve from 0.22198\n423/423 [==============================] - 96s 226ms/step - loss: 0.2122 - binary_accuracy: 0.9152 - val_loss: 0.2271 - val_binary_accuracy: 0.9089\nEpoch 58/60\n423/423 [==============================] - ETA: 0s - loss: 0.2124 - binary_accuracy: 0.9150\nEpoch 59: val_loss did not improve from 0.22198\n423/423 [==============================] - 95s 224ms/step - loss: 0.2124 - binary_accuracy: 0.9150 - val_loss: 0.2282 - val_binary_accuracy: 0.9088\nEpoch 60/60\n423/423 [==============================] - ETA: 0s - loss: 0.2112 - binary_accuracy: 0.9158\nEpoch 60: val_loss did not improve from 0.22198\n423/423 [==============================] - 99s 233ms/step - loss: 0.2112 - binary_accuracy: 0.9158 - val_loss: 0.2292 - val_binary_accuracy: 0.9097\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7c6102e130a0>"},"metadata":{}}]},{"cell_type":"code","source":"experiment.log_model(\"Facial_r\", filepath)\nexperiment.end()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T03:25:24.956094Z","iopub.execute_input":"2023-11-25T03:25:24.956408Z","iopub.status.idle":"2023-11-25T03:25:30.919774Z","shell.execute_reply.started":"2023-11-25T03:25:24.956381Z","shell.execute_reply":"2023-11-25T03:25:30.919024Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/gurumasterahb/regularizer/60981e5d06944e77aa46274cff0a6293\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_binary_accuracy [2580]         : (0.4555920958518982, 0.9247533082962036)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_loss [2580]                    : (0.1908176690340042, 0.7998648881912231)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     binary_accuracy [60]                 : (0.807835578918457, 0.9158098697662354)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch_duration [60]                  : (87.31936238599974, 262.91889875200013)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [60]                            : (0.21118652820587158, 0.5218352675437927)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_binary_accuracy [60]             : (0.8180146813392639, 0.9116355776786804)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_loss [60]                        : (0.22198352217674255, 0.47353890538215637)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validate_batch_binary_accuracy [360] : (0.8125, 0.9198191165924072)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validate_batch_loss [360]            : (0.20222169160842896, 0.4826835095882416)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name             : Try_5 [from: FunctionalAPI]\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainable_params : 5018086\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Optimizer                       : RMSprop\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_centered                : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_clipnorm                : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_clipvalue               : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_ema_momentum            : 0.99\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_ema_overwrite_frequency : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_epsilon                 : 1e-07\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_global_clipnorm         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_is_legacy_optimizer     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_jit_compile             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_learning_rate           : 0.0010000000474974513\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_momentum                : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_name                    : RMSprop\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_rho                     : 0.9\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_use_ema                 : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_weight_decay            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size                      : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs                          : 60\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss                            : binary_crossentropy\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_class                       : 38\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_test                        : 19962\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train                       : 162770\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_val                         : 19867\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer                       : RMSprop\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     steps                           : 423\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     histogram3d                  : 1708\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element                : 1 (38.39 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 22.03 MB/38.39 MB\n","output_type":"stream"}]}]}