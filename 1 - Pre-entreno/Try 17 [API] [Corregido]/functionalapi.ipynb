{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7028419,"sourceType":"datasetVersion","datasetId":4042417}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Para llevar el registro\n!pip install -q comet_ml\nimport comet_ml\ncomet_ml.init(project_name = 'Regularizer')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:11:55.656845Z","iopub.execute_input":"2023-11-24T22:11:55.657356Z","iopub.status.idle":"2023-11-24T22:12:25.654635Z","shell.execute_reply.started":"2023-11-24T22:11:55.657328Z","shell.execute_reply":"2023-11-24T22:12:25.653810Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mPlease paste your Comet API key from https://www.comet.com/api/my/settings/\n(api key may not show as you type)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Comet API key:  ·························\n"},{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Conv2D, MaxPooling2D, Concatenate\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adadelta\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.regularizers import l2","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:12:25.656198Z","iopub.execute_input":"2023-11-24T22:12:25.656498Z","iopub.status.idle":"2023-11-24T22:12:37.162571Z","shell.execute_reply.started":"2023-11-24T22:12:25.656473Z","shell.execute_reply":"2023-11-24T22:12:37.161612Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Se crea el experimento en Comet\nexperiment = comet_ml.Experiment(\n    auto_histogram_weight_logging = True,\n    auto_histogram_gradient_logging = True,\n    auto_histogram_activation_logging = True,\n    log_code = True\n)\nexperiment.set_name('Try_4 [from: FunctionalAPI]')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:12:37.163716Z","iopub.execute_input":"2023-11-24T22:12:37.164258Z","iopub.status.idle":"2023-11-24T22:12:41.224834Z","shell.execute_reply.started":"2023-11-24T22:12:37.164230Z","shell.execute_reply":"2023-11-24T22:12:41.223913Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/gurumasterahb/regularizer/e40af02936724087a7113433783b1e59\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cargar los datos de los txt\nfile_attr = os.path.join('/kaggle/input/img-align-celeba-partition/attr.csv')\nattr = pd.read_csv(file_attr)\n\n# Imágenes\ni_test = '/kaggle/input/img-align-celeba-partition/align_partition/align_test'\ni_train = '/kaggle/input/img-align-celeba-partition/align_partition/align_train'\ni_val = '/kaggle/input/img-align-celeba-partition/align_partition/align_val'","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:12:41.227470Z","iopub.execute_input":"2023-11-24T22:12:41.228248Z","iopub.status.idle":"2023-11-24T22:12:42.111509Z","shell.execute_reply.started":"2023-11-24T22:12:41.228214Z","shell.execute_reply":"2023-11-24T22:12:42.110513Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Parámetros\ni_width = int(178 * 1.2)\ni_height = int(218 * 1.2)\ninput_shape = (i_width, i_height, 3)\n\nparameters = {\n    'num_class' : 38,\n    'epochs' : 60,\n    'batch_size' : 64,\n    'loss' : 'binary_crossentropy',\n    'optimizer' : 'RMSprop',\n    'num_train' : 162770,\n    'num_val' : 19867,\n    'num_test' : 19962,\n}\nexperiment.log_parameters(parameters)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:12:42.112727Z","iopub.execute_input":"2023-11-24T22:12:42.113610Z","iopub.status.idle":"2023-11-24T22:12:42.190156Z","shell.execute_reply.started":"2023-11-24T22:12:42.113573Z","shell.execute_reply":"2023-11-24T22:12:42.189314Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Solo toma el entero\nepoch_steps = parameters['num_train'] // (parameters['batch_size'] * 6) # Training\nval_steps = parameters['num_val'] // (parameters['batch_size'] * 6) # Validation\ntest_steps = parameters['num_test'] // (parameters['batch_size'] * 6) # Testing","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:12:42.191312Z","iopub.execute_input":"2023-11-24T22:12:42.191634Z","iopub.status.idle":"2023-11-24T22:12:42.197229Z","shell.execute_reply.started":"2023-11-24T22:12:42.191606Z","shell.execute_reply":"2023-11-24T22:12:42.196226Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"gen_train = ImageDataGenerator(rescale = 1./255.)\ntrain = gen_train.flow_from_dataframe(\n    attr,\n    directory = i_train,\n    x_col = attr.columns[0],  # Nombre de la columna que contiene los nombres de las imágenes\n    y_col = attr.columns[1:],  # Lista de nombres de las columnas de atributos\n    target_size = (i_width, i_height),\n    batch_size = parameters['batch_size'],\n    class_mode = 'raw',\n    shuffle = True\n)\n\ngen_val = ImageDataGenerator(rescale = 1./255.)\nval = gen_val.flow_from_dataframe(\n    attr,\n    directory = i_val,\n    x_col = attr.columns[0],  # Nombre de la columna que contiene los nombres de las imágenes\n    y_col = attr.columns[1:],  # Lista de nombres de las columnas de atributos\n    target_size = (i_width, i_height),\n    batch_size = parameters['batch_size'],\n    class_mode = 'raw',\n    shuffle = True\n)\n\ngen_testing = ImageDataGenerator(rescale = 1./255.)\ntest = gen_testing.flow_from_dataframe(\n    attr,\n    directory = i_test,\n    x_col = attr.columns[0],  # Nombre de la columna que contiene los nombres de las imágenes\n    y_col = attr.columns[1:],  # Lista de nombres de las columnas de atributos\n    target_size = (i_width, i_height),\n    batch_size = parameters['batch_size'],\n    class_mode = 'raw',\n    shuffle = True\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:12:42.198792Z","iopub.execute_input":"2023-11-24T22:12:42.199141Z","iopub.status.idle":"2023-11-24T22:23:46.417023Z","shell.execute_reply.started":"2023-11-24T22:12:42.199107Z","shell.execute_reply":"2023-11-24T22:23:46.416092Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 162770 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 39829 invalid image filename(s) in x_col=\"202599\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 19867 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 182732 invalid image filename(s) in x_col=\"202599\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 19962 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 182637 invalid image filename(s) in x_col=\"202599\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Arquitectura\n# Functional API\ninputs = Input(shape = input_shape)\n\nconv1 = Conv2D(32, (3,3), activation = 'relu')(inputs)\nmpool1 = MaxPooling2D(pool_size = (2,2))(conv1)\n\nconv2 = Conv2D(64, (3,3), activation = 'PReLU', kernel_regularizer = l2(0.0001))(mpool1)\nmpool2 = MaxPooling2D(pool_size = (2,2))(conv2)\n\nconv3 = Conv2D(128, (3,3), activation = 'PReLU')(mpool2)\nmpool3 = MaxPooling2D(pool_size = (2,2))(conv3)\n\nconv4 = Conv2D(256, (3,3), activation = 'PReLU')(mpool3)\nmpool4 = MaxPooling2D(pool_size = (2,2))(conv4)\n\nconv5 = Conv2D(512, (3,3), activation = 'PReLU', kernel_regularizer = l2(0.0001))(mpool4)\nmpool5 = MaxPooling2D(pool_size = (2,2))(conv5)\n\nconv6 = Conv2D(256, (3,3), activation = 'relu')(mpool5)\nmpool6 = MaxPooling2D(pool_size = (2,2))(conv6)\n\nx = Flatten()(mpool6)\n\nx_1 = Dense(512, activation = 'PReLU')(x)\nx_2 = Dense(512, activation = 'PReLU')(x)\n\nx = Concatenate()([x_1, x_2])\n# x = Dropout(0.25)(x)\n\nx = Dense(1024, activation = 'relu')(x)\nx = Dropout(0.15)(x)\n\nx = Dense(512, activation = 'PReLU', kernel_regularizer = l2(0.0001))(x)\n\nx = Dense(256, activation = 'PReLU')(x)\n\nx = Dense(128, activation = 'relu')(x)\n\nX = Dense(parameters['num_class'], activation = 'sigmoid')(x)\n\nmodel = tf.keras.Model(inputs = inputs, outputs = X)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:23:46.418199Z","iopub.execute_input":"2023-11-24T22:23:46.418509Z","iopub.status.idle":"2023-11-24T22:23:49.665320Z","shell.execute_reply.started":"2023-11-24T22:23:46.418485Z","shell.execute_reply":"2023-11-24T22:23:49.664287Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 213, 261, 3)]        0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 211, 259, 32)         896       ['input_1[0][0]']             \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 105, 129, 32)         0         ['conv2d[0][0]']              \n D)                                                                                               \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 103, 127, 64)         855680    ['max_pooling2d[0][0]']       \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 51, 63, 64)           0         ['conv2d_1[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 49, 61, 128)          456448    ['max_pooling2d_1[0][0]']     \n                                                                                                  \n max_pooling2d_2 (MaxPoolin  (None, 24, 30, 128)          0         ['conv2d_2[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 22, 28, 256)          452864    ['max_pooling2d_2[0][0]']     \n                                                                                                  \n max_pooling2d_3 (MaxPoolin  (None, 11, 14, 256)          0         ['conv2d_3[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 9, 12, 512)           1235456   ['max_pooling2d_3[0][0]']     \n                                                                                                  \n max_pooling2d_4 (MaxPoolin  (None, 4, 6, 512)            0         ['conv2d_4[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 2, 4, 256)            1179904   ['max_pooling2d_4[0][0]']     \n                                                                                                  \n max_pooling2d_5 (MaxPoolin  (None, 1, 2, 256)            0         ['conv2d_5[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n flatten (Flatten)           (None, 512)                  0         ['max_pooling2d_5[0][0]']     \n                                                                                                  \n dense (Dense)               (None, 512)                  263168    ['flatten[0][0]']             \n                                                                                                  \n dense_1 (Dense)             (None, 512)                  263168    ['flatten[0][0]']             \n                                                                                                  \n concatenate (Concatenate)   (None, 1024)                 0         ['dense[0][0]',               \n                                                                     'dense_1[0][0]']             \n                                                                                                  \n dense_2 (Dense)             (None, 1024)                 1049600   ['concatenate[0][0]']         \n                                                                                                  \n dropout (Dropout)           (None, 1024)                 0         ['dense_2[0][0]']             \n                                                                                                  \n dense_3 (Dense)             (None, 512)                  525312    ['dropout[0][0]']             \n                                                                                                  \n dense_4 (Dense)             (None, 256)                  131584    ['dense_3[0][0]']             \n                                                                                                  \n dense_5 (Dense)             (None, 128)                  32896     ['dense_4[0][0]']             \n                                                                                                  \n dense_6 (Dense)             (None, 38)                   4902      ['dense_5[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 6451878 (24.61 MB)\nTrainable params: 6451878 (24.61 MB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Checkpoint para el mejor modelo (val_accuracy)\nfilepath = 'best_val_loss.h5'\ncheckpoint = ModelCheckpoint(\n    filepath,\n    monitor = 'val_loss',\n    verbose = 1,\n    save_best_only = True,\n    mode = 'min'\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:23:49.666738Z","iopub.execute_input":"2023-11-24T22:23:49.667412Z","iopub.status.idle":"2023-11-24T22:23:49.672758Z","shell.execute_reply.started":"2023-11-24T22:23:49.667375Z","shell.execute_reply":"2023-11-24T22:23:49.671680Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Compilación y entrenamiento\nmodel.compile(\n    loss = parameters['loss'],\n    optimizer = RMSprop(learning_rate = 0.001),\n    metrics = ['binary_accuracy']\n)\n\nmodel.fit(\n    train,\n    batch_size = parameters['batch_size'],\n    epochs = parameters['epochs'],\n    verbose = 1,\n    validation_data = val,\n    steps_per_epoch = epoch_steps,\n    validation_steps = val_steps,\n    callbacks = [checkpoint]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T22:23:49.675922Z","iopub.execute_input":"2023-11-24T22:23:49.676257Z","iopub.status.idle":"2023-11-25T00:12:21.309682Z","shell.execute_reply.started":"2023-11-24T22:23:49.676226Z","shell.execute_reply":"2023-11-25T00:12:21.308729Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m auto_histogram_gradient_logging is True, but inputs and targets are not available; unable to log gradients\n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m auto_histogram_activation_logging is True, but inputs are not available; unable to log activations\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/60\n423/423 [==============================] - ETA: 0s - loss: 0.5213 - binary_accuracy: 0.8078\nEpoch 1: val_loss improved from inf to 0.48601, saving model to best_val_loss.h5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"423/423 [==============================] - 217s 482ms/step - loss: 0.5213 - binary_accuracy: 0.8078 - val_loss: 0.4860 - val_binary_accuracy: 0.8138\nEpoch 2/60\n423/423 [==============================] - ETA: 0s - loss: 0.4709 - binary_accuracy: 0.8107\nEpoch 2: val_loss improved from 0.48601 to 0.45941, saving model to best_val_loss.h5\n423/423 [==============================] - 192s 454ms/step - loss: 0.4709 - binary_accuracy: 0.8107 - val_loss: 0.4594 - val_binary_accuracy: 0.8107\nEpoch 3/60\n423/423 [==============================] - ETA: 0s - loss: 0.4036 - binary_accuracy: 0.8362\nEpoch 3: val_loss improved from 0.45941 to 0.38163, saving model to best_val_loss.h5\n423/423 [==============================] - 178s 421ms/step - loss: 0.4036 - binary_accuracy: 0.8362 - val_loss: 0.3816 - val_binary_accuracy: 0.8439\nEpoch 4/60\n423/423 [==============================] - ETA: 0s - loss: 0.3513 - binary_accuracy: 0.8580\nEpoch 4: val_loss improved from 0.38163 to 0.32895, saving model to best_val_loss.h5\n423/423 [==============================] - 165s 390ms/step - loss: 0.3513 - binary_accuracy: 0.8580 - val_loss: 0.3289 - val_binary_accuracy: 0.8681\nEpoch 5/60\n423/423 [==============================] - ETA: 0s - loss: 0.3192 - binary_accuracy: 0.8681\nEpoch 5: val_loss improved from 0.32895 to 0.29964, saving model to best_val_loss.h5\n423/423 [==============================] - 153s 360ms/step - loss: 0.3192 - binary_accuracy: 0.8681 - val_loss: 0.2996 - val_binary_accuracy: 0.8757\nEpoch 6/60\n423/423 [==============================] - ETA: 0s - loss: 0.2980 - binary_accuracy: 0.8748\nEpoch 6: val_loss improved from 0.29964 to 0.28223, saving model to best_val_loss.h5\n423/423 [==============================] - 144s 341ms/step - loss: 0.2980 - binary_accuracy: 0.8748 - val_loss: 0.2822 - val_binary_accuracy: 0.8815\nEpoch 7/60\n423/423 [==============================] - ETA: 0s - loss: 0.2846 - binary_accuracy: 0.8798\nEpoch 7: val_loss improved from 0.28223 to 0.26998, saving model to best_val_loss.h5\n423/423 [==============================] - 133s 315ms/step - loss: 0.2846 - binary_accuracy: 0.8798 - val_loss: 0.2700 - val_binary_accuracy: 0.8867\nEpoch 8/60\n423/423 [==============================] - ETA: 0s - loss: 0.2753 - binary_accuracy: 0.8837\nEpoch 8: val_loss did not improve from 0.26998\n423/423 [==============================] - 127s 301ms/step - loss: 0.2753 - binary_accuracy: 0.8837 - val_loss: 0.2732 - val_binary_accuracy: 0.8855\nEpoch 9/60\n423/423 [==============================] - ETA: 0s - loss: 0.2670 - binary_accuracy: 0.8870\nEpoch 9: val_loss improved from 0.26998 to 0.25907, saving model to best_val_loss.h5\n423/423 [==============================] - 126s 297ms/step - loss: 0.2670 - binary_accuracy: 0.8870 - val_loss: 0.2591 - val_binary_accuracy: 0.8912\nEpoch 10/60\n423/423 [==============================] - ETA: 0s - loss: 0.2612 - binary_accuracy: 0.8893\nEpoch 10: val_loss improved from 0.25907 to 0.25517, saving model to best_val_loss.h5\n423/423 [==============================] - 119s 280ms/step - loss: 0.2612 - binary_accuracy: 0.8893 - val_loss: 0.2552 - val_binary_accuracy: 0.8930\nEpoch 11/60\n423/423 [==============================] - ETA: 0s - loss: 0.2561 - binary_accuracy: 0.8914\nEpoch 11: val_loss improved from 0.25517 to 0.25102, saving model to best_val_loss.h5\n423/423 [==============================] - 117s 275ms/step - loss: 0.2561 - binary_accuracy: 0.8914 - val_loss: 0.2510 - val_binary_accuracy: 0.8948\nEpoch 12/60\n423/423 [==============================] - ETA: 0s - loss: 0.2515 - binary_accuracy: 0.8937\nEpoch 12: val_loss improved from 0.25102 to 0.24390, saving model to best_val_loss.h5\n423/423 [==============================] - 114s 269ms/step - loss: 0.2515 - binary_accuracy: 0.8937 - val_loss: 0.2439 - val_binary_accuracy: 0.8989\nEpoch 13/60\n423/423 [==============================] - ETA: 0s - loss: 0.2491 - binary_accuracy: 0.8951\nEpoch 13: val_loss improved from 0.24390 to 0.23992, saving model to best_val_loss.h5\n423/423 [==============================] - 109s 257ms/step - loss: 0.2491 - binary_accuracy: 0.8951 - val_loss: 0.2399 - val_binary_accuracy: 0.9006\nEpoch 14/60\n423/423 [==============================] - ETA: 0s - loss: 0.2445 - binary_accuracy: 0.8970\nEpoch 14: val_loss did not improve from 0.23992\n423/423 [==============================] - 107s 253ms/step - loss: 0.2445 - binary_accuracy: 0.8970 - val_loss: 0.2405 - val_binary_accuracy: 0.9003\nEpoch 15/60\n423/423 [==============================] - ETA: 0s - loss: 0.2426 - binary_accuracy: 0.8979\nEpoch 15: val_loss improved from 0.23992 to 0.23898, saving model to best_val_loss.h5\n423/423 [==============================] - 104s 246ms/step - loss: 0.2426 - binary_accuracy: 0.8979 - val_loss: 0.2390 - val_binary_accuracy: 0.9004\nEpoch 16/60\n423/423 [==============================] - ETA: 0s - loss: 0.2409 - binary_accuracy: 0.8990\nEpoch 16: val_loss did not improve from 0.23898\n423/423 [==============================] - 101s 239ms/step - loss: 0.2409 - binary_accuracy: 0.8990 - val_loss: 0.2392 - val_binary_accuracy: 0.9012\nEpoch 17/60\n423/423 [==============================] - ETA: 0s - loss: 0.2378 - binary_accuracy: 0.9005\nEpoch 17: val_loss improved from 0.23898 to 0.23851, saving model to best_val_loss.h5\n423/423 [==============================] - 97s 229ms/step - loss: 0.2378 - binary_accuracy: 0.9005 - val_loss: 0.2385 - val_binary_accuracy: 0.9004\nEpoch 18/60\n423/423 [==============================] - ETA: 0s - loss: 0.2375 - binary_accuracy: 0.9008\nEpoch 18: val_loss improved from 0.23851 to 0.23560, saving model to best_val_loss.h5\n423/423 [==============================] - 97s 230ms/step - loss: 0.2375 - binary_accuracy: 0.9008 - val_loss: 0.2356 - val_binary_accuracy: 0.9037\nEpoch 19/60\n423/423 [==============================] - ETA: 0s - loss: 0.2354 - binary_accuracy: 0.9015\nEpoch 19: val_loss improved from 0.23560 to 0.23312, saving model to best_val_loss.h5\n423/423 [==============================] - 96s 226ms/step - loss: 0.2354 - binary_accuracy: 0.9015 - val_loss: 0.2331 - val_binary_accuracy: 0.9039\nEpoch 20/60\n423/423 [==============================] - ETA: 0s - loss: 0.2337 - binary_accuracy: 0.9025\nEpoch 20: val_loss improved from 0.23312 to 0.22983, saving model to best_val_loss.h5\n423/423 [==============================] - 94s 223ms/step - loss: 0.2337 - binary_accuracy: 0.9025 - val_loss: 0.2298 - val_binary_accuracy: 0.9056\nEpoch 21/60\n423/423 [==============================] - ETA: 0s - loss: 0.2314 - binary_accuracy: 0.9038\nEpoch 21: val_loss did not improve from 0.22983\n423/423 [==============================] - 93s 219ms/step - loss: 0.2314 - binary_accuracy: 0.9038 - val_loss: 0.2351 - val_binary_accuracy: 0.9033\nEpoch 22/60\n423/423 [==============================] - ETA: 0s - loss: 0.2304 - binary_accuracy: 0.9045\nEpoch 22: val_loss improved from 0.22983 to 0.22972, saving model to best_val_loss.h5\n423/423 [==============================] - 94s 221ms/step - loss: 0.2304 - binary_accuracy: 0.9045 - val_loss: 0.2297 - val_binary_accuracy: 0.9056\nEpoch 23/60\n423/423 [==============================] - ETA: 0s - loss: 0.2292 - binary_accuracy: 0.9050\nEpoch 23: val_loss did not improve from 0.22972\n423/423 [==============================] - 93s 219ms/step - loss: 0.2292 - binary_accuracy: 0.9050 - val_loss: 0.2304 - val_binary_accuracy: 0.9058\nEpoch 24/60\n423/423 [==============================] - ETA: 0s - loss: 0.2285 - binary_accuracy: 0.9051\nEpoch 24: val_loss improved from 0.22972 to 0.22867, saving model to best_val_loss.h5\n423/423 [==============================] - 92s 218ms/step - loss: 0.2285 - binary_accuracy: 0.9051 - val_loss: 0.2287 - val_binary_accuracy: 0.9073\nEpoch 25/60\n423/423 [==============================] - ETA: 0s - loss: 0.2270 - binary_accuracy: 0.9061\nEpoch 25: val_loss improved from 0.22867 to 0.22637, saving model to best_val_loss.h5\n423/423 [==============================] - 89s 211ms/step - loss: 0.2270 - binary_accuracy: 0.9061 - val_loss: 0.2264 - val_binary_accuracy: 0.9069\nEpoch 26/60\n423/423 [==============================] - ETA: 0s - loss: 0.2263 - binary_accuracy: 0.9064\nEpoch 26: val_loss did not improve from 0.22637\n423/423 [==============================] - 92s 217ms/step - loss: 0.2263 - binary_accuracy: 0.9064 - val_loss: 0.2279 - val_binary_accuracy: 0.9073\nEpoch 27/60\n423/423 [==============================] - ETA: 0s - loss: 0.2249 - binary_accuracy: 0.9071\nEpoch 27: val_loss did not improve from 0.22637\n423/423 [==============================] - 90s 212ms/step - loss: 0.2249 - binary_accuracy: 0.9071 - val_loss: 0.2355 - val_binary_accuracy: 0.9038\nEpoch 28/60\n423/423 [==============================] - ETA: 0s - loss: 0.2240 - binary_accuracy: 0.9078\nEpoch 28: val_loss did not improve from 0.22637\n423/423 [==============================] - 92s 217ms/step - loss: 0.2240 - binary_accuracy: 0.9078 - val_loss: 0.2268 - val_binary_accuracy: 0.9075\nEpoch 29/60\n423/423 [==============================] - ETA: 0s - loss: 0.2232 - binary_accuracy: 0.9083\nEpoch 29: val_loss improved from 0.22637 to 0.22562, saving model to best_val_loss.h5\n423/423 [==============================] - 91s 214ms/step - loss: 0.2232 - binary_accuracy: 0.9083 - val_loss: 0.2256 - val_binary_accuracy: 0.9089\nEpoch 30/60\n423/423 [==============================] - ETA: 0s - loss: 0.2225 - binary_accuracy: 0.9083\nEpoch 30: val_loss did not improve from 0.22562\n423/423 [==============================] - 91s 214ms/step - loss: 0.2225 - binary_accuracy: 0.9083 - val_loss: 0.2275 - val_binary_accuracy: 0.9072\nEpoch 31/60\n423/423 [==============================] - ETA: 0s - loss: 0.2221 - binary_accuracy: 0.9085\nEpoch 31: val_loss improved from 0.22562 to 0.22350, saving model to best_val_loss.h5\n423/423 [==============================] - 89s 211ms/step - loss: 0.2221 - binary_accuracy: 0.9085 - val_loss: 0.2235 - val_binary_accuracy: 0.9088\nEpoch 32/60\n423/423 [==============================] - ETA: 0s - loss: 0.2214 - binary_accuracy: 0.9092\nEpoch 32: val_loss did not improve from 0.22350\n423/423 [==============================] - 90s 212ms/step - loss: 0.2214 - binary_accuracy: 0.9092 - val_loss: 0.2262 - val_binary_accuracy: 0.9079\nEpoch 33/60\n423/423 [==============================] - ETA: 0s - loss: 0.2200 - binary_accuracy: 0.9096\nEpoch 33: val_loss did not improve from 0.22350\n423/423 [==============================] - 90s 212ms/step - loss: 0.2200 - binary_accuracy: 0.9096 - val_loss: 0.2308 - val_binary_accuracy: 0.9072\nEpoch 34/60\n423/423 [==============================] - ETA: 0s - loss: 0.2188 - binary_accuracy: 0.9102\nEpoch 34: val_loss did not improve from 0.22350\n423/423 [==============================] - 90s 213ms/step - loss: 0.2188 - binary_accuracy: 0.9102 - val_loss: 0.2273 - val_binary_accuracy: 0.9067\nEpoch 35/60\n423/423 [==============================] - ETA: 0s - loss: 0.2194 - binary_accuracy: 0.9099\nEpoch 35: val_loss did not improve from 0.22350\n423/423 [==============================] - 89s 211ms/step - loss: 0.2194 - binary_accuracy: 0.9099 - val_loss: 0.2263 - val_binary_accuracy: 0.9089\nEpoch 36/60\n423/423 [==============================] - ETA: 0s - loss: 0.2179 - binary_accuracy: 0.9110\nEpoch 36: val_loss improved from 0.22350 to 0.22176, saving model to best_val_loss.h5\n423/423 [==============================] - 90s 213ms/step - loss: 0.2179 - binary_accuracy: 0.9110 - val_loss: 0.2218 - val_binary_accuracy: 0.9099\nEpoch 37/60\n423/423 [==============================] - ETA: 0s - loss: 0.2175 - binary_accuracy: 0.9111\nEpoch 37: val_loss did not improve from 0.22176\n423/423 [==============================] - 90s 212ms/step - loss: 0.2175 - binary_accuracy: 0.9111 - val_loss: 0.2241 - val_binary_accuracy: 0.9100\nEpoch 38/60\n423/423 [==============================] - ETA: 0s - loss: 0.2171 - binary_accuracy: 0.9113\nEpoch 38: val_loss did not improve from 0.22176\n423/423 [==============================] - 90s 213ms/step - loss: 0.2171 - binary_accuracy: 0.9113 - val_loss: 0.2232 - val_binary_accuracy: 0.9095\nEpoch 39/60\n423/423 [==============================] - ETA: 0s - loss: 0.2154 - binary_accuracy: 0.9122\nEpoch 39: val_loss improved from 0.22176 to 0.22170, saving model to best_val_loss.h5\n423/423 [==============================] - 91s 215ms/step - loss: 0.2154 - binary_accuracy: 0.9122 - val_loss: 0.2217 - val_binary_accuracy: 0.9110\nEpoch 40/60\n423/423 [==============================] - ETA: 0s - loss: 0.2160 - binary_accuracy: 0.9122\nEpoch 40: val_loss did not improve from 0.22170\n423/423 [==============================] - 90s 211ms/step - loss: 0.2160 - binary_accuracy: 0.9122 - val_loss: 0.2231 - val_binary_accuracy: 0.9091\nEpoch 41/60\n423/423 [==============================] - ETA: 0s - loss: 0.2162 - binary_accuracy: 0.9120\nEpoch 41: val_loss did not improve from 0.22170\n423/423 [==============================] - 91s 215ms/step - loss: 0.2162 - binary_accuracy: 0.9120 - val_loss: 0.2252 - val_binary_accuracy: 0.9095\nEpoch 42/60\n423/423 [==============================] - ETA: 0s - loss: 0.2147 - binary_accuracy: 0.9126\nEpoch 42: val_loss did not improve from 0.22170\n423/423 [==============================] - 88s 209ms/step - loss: 0.2147 - binary_accuracy: 0.9126 - val_loss: 0.2246 - val_binary_accuracy: 0.9089\nEpoch 43/60\n423/423 [==============================] - ETA: 0s - loss: 0.2142 - binary_accuracy: 0.9128\nEpoch 43: val_loss did not improve from 0.22170\n423/423 [==============================] - 90s 212ms/step - loss: 0.2142 - binary_accuracy: 0.9128 - val_loss: 0.2281 - val_binary_accuracy: 0.9074\nEpoch 44/60\n423/423 [==============================] - ETA: 0s - loss: 0.2136 - binary_accuracy: 0.9135\nEpoch 44: val_loss did not improve from 0.22170\n423/423 [==============================] - 90s 212ms/step - loss: 0.2136 - binary_accuracy: 0.9135 - val_loss: 0.2238 - val_binary_accuracy: 0.9105\nEpoch 45/60\n423/423 [==============================] - ETA: 0s - loss: 0.2137 - binary_accuracy: 0.9134\nEpoch 45: val_loss did not improve from 0.22170\n423/423 [==============================] - 91s 216ms/step - loss: 0.2137 - binary_accuracy: 0.9134 - val_loss: 0.2223 - val_binary_accuracy: 0.9110\nEpoch 46/60\n423/423 [==============================] - ETA: 0s - loss: 0.2127 - binary_accuracy: 0.9139\nEpoch 46: val_loss did not improve from 0.22170\n423/423 [==============================] - 94s 222ms/step - loss: 0.2127 - binary_accuracy: 0.9139 - val_loss: 0.2234 - val_binary_accuracy: 0.9101\nEpoch 47/60\n423/423 [==============================] - ETA: 0s - loss: 0.2134 - binary_accuracy: 0.9137\nEpoch 47: val_loss improved from 0.22170 to 0.21834, saving model to best_val_loss.h5\n423/423 [==============================] - 94s 222ms/step - loss: 0.2134 - binary_accuracy: 0.9137 - val_loss: 0.2183 - val_binary_accuracy: 0.9129\nEpoch 48/60\n423/423 [==============================] - ETA: 0s - loss: 0.2125 - binary_accuracy: 0.9142\nEpoch 48: val_loss did not improve from 0.21834\n423/423 [==============================] - 94s 222ms/step - loss: 0.2125 - binary_accuracy: 0.9142 - val_loss: 0.2195 - val_binary_accuracy: 0.9114\nEpoch 49/60\n423/423 [==============================] - ETA: 0s - loss: 0.2116 - binary_accuracy: 0.9149\nEpoch 49: val_loss did not improve from 0.21834\n423/423 [==============================] - 95s 225ms/step - loss: 0.2116 - binary_accuracy: 0.9149 - val_loss: 0.2268 - val_binary_accuracy: 0.9089\nEpoch 50/60\n423/423 [==============================] - ETA: 0s - loss: 0.2113 - binary_accuracy: 0.9146\nEpoch 51: val_loss did not improve from 0.21834\n423/423 [==============================] - 96s 226ms/step - loss: 0.2113 - binary_accuracy: 0.9146 - val_loss: 0.2215 - val_binary_accuracy: 0.9118\nEpoch 52/60\n423/423 [==============================] - ETA: 0s - loss: 0.2105 - binary_accuracy: 0.9151\nEpoch 52: val_loss did not improve from 0.21834\n423/423 [==============================] - 97s 228ms/step - loss: 0.2105 - binary_accuracy: 0.9151 - val_loss: 0.2235 - val_binary_accuracy: 0.9097\nEpoch 53/60\n423/423 [==============================] - ETA: 0s - loss: 0.2104 - binary_accuracy: 0.9154\nEpoch 53: val_loss did not improve from 0.21834\n423/423 [==============================] - 97s 228ms/step - loss: 0.2104 - binary_accuracy: 0.9154 - val_loss: 0.2196 - val_binary_accuracy: 0.9117\nEpoch 54/60\n423/423 [==============================] - ETA: 0s - loss: 0.2101 - binary_accuracy: 0.9157\nEpoch 54: val_loss did not improve from 0.21834\n423/423 [==============================] - 97s 228ms/step - loss: 0.2101 - binary_accuracy: 0.9157 - val_loss: 0.2203 - val_binary_accuracy: 0.9121\nEpoch 55/60\n423/423 [==============================] - ETA: 0s - loss: 0.2095 - binary_accuracy: 0.9157\nEpoch 55: val_loss did not improve from 0.21834\n423/423 [==============================] - 97s 229ms/step - loss: 0.2095 - binary_accuracy: 0.9157 - val_loss: 0.2243 - val_binary_accuracy: 0.9100\nEpoch 56/60\n423/423 [==============================] - ETA: 0s - loss: 0.2092 - binary_accuracy: 0.9162\nEpoch 56: val_loss did not improve from 0.21834\n423/423 [==============================] - 94s 223ms/step - loss: 0.2092 - binary_accuracy: 0.9162 - val_loss: 0.2206 - val_binary_accuracy: 0.9120\nEpoch 57/60\n423/423 [==============================] - ETA: 0s - loss: 0.2091 - binary_accuracy: 0.9160\nEpoch 57: val_loss did not improve from 0.21834\n423/423 [==============================] - 95s 225ms/step - loss: 0.2091 - binary_accuracy: 0.9160 - val_loss: 0.2204 - val_binary_accuracy: 0.9137\nEpoch 58/60\n423/423 [==============================] - ETA: 0s - loss: 0.2094 - binary_accuracy: 0.9160\nEpoch 58: val_loss did not improve from 0.21834\n423/423 [==============================] - 94s 222ms/step - loss: 0.2094 - binary_accuracy: 0.9160 - val_loss: 0.2233 - val_binary_accuracy: 0.9108\nEpoch 59/60\n423/423 [==============================] - ETA: 0s - loss: 0.2085 - binary_accuracy: 0.9164\nEpoch 59: val_loss did not improve from 0.21834\n423/423 [==============================] - 93s 221ms/step - loss: 0.2085 - binary_accuracy: 0.9164 - val_loss: 0.2247 - val_binary_accuracy: 0.9117\nEpoch 60/60\n423/423 [==============================] - ETA: 0s - loss: 0.2080 - binary_accuracy: 0.9168\nEpoch 60: val_loss did not improve from 0.21834\n423/423 [==============================] - 93s 219ms/step - loss: 0.2080 - binary_accuracy: 0.9168 - val_loss: 0.2205 - val_binary_accuracy: 0.9122\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7869c7854160>"},"metadata":{}}]},{"cell_type":"code","source":"experiment.log_model(\"Facial_r\", filepath)\nexperiment.end()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T00:12:21.310746Z","iopub.execute_input":"2023-11-25T00:12:21.311023Z","iopub.status.idle":"2023-11-25T00:12:25.256979Z","shell.execute_reply.started":"2023-11-25T00:12:21.310999Z","shell.execute_reply":"2023-11-25T00:12:25.256029Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/gurumasterahb/regularizer/e40af02936724087a7113433783b1e59\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_binary_accuracy [2580]         : (0.4658717215061188, 0.9268091917037964)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_loss [2580]                    : (0.18715567886829376, 0.8471132516860962)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     binary_accuracy [60]                 : (0.8077900409698486, 0.9168217182159424)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch_duration [60]                  : (87.52718287900007, 217.11129162099996)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [60]                            : (0.20797620713710785, 0.5212895274162292)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_binary_accuracy [60]             : (0.8107342720031738, 0.9137320518493652)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_loss [60]                        : (0.2183409482240677, 0.4860137403011322)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validate_batch_binary_accuracy [360] : (0.8046875, 0.9222861528396606)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     validate_batch_loss [360]            : (0.20074544847011566, 0.4949961006641388)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name             : Try_4 [from: FunctionalAPI]\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainable_params : 6451878\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Optimizer                       : RMSprop\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_centered                : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_clipnorm                : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_clipvalue               : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_ema_momentum            : 0.99\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_ema_overwrite_frequency : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_epsilon                 : 1e-07\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_global_clipnorm         : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_is_legacy_optimizer     : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_jit_compile             : True\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_learning_rate           : 0.0010000000474974513\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_momentum                : 0.0\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_name                    : RMSprop\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_rho                     : 0.9\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_use_ema                 : False\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     RMSprop_weight_decay            : None\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size                      : 64\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs                          : 60\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss                            : binary_crossentropy\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_class                       : 38\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_test                        : 19962\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train                       : 162770\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_val                         : 19867\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer                       : RMSprop\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     steps                           : 423\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     histogram3d                  : 2074\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element                : 1 (49.34 MB)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","output_type":"stream"}]}]}